#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ v12.0 (å®Œå…¨çµ±åˆç‰ˆ)

æ”¹ç‰ˆå±¥æ­´:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ â”‚    æ›´æ–°æ—¥    â”‚  æ›´æ–°è€…  â”‚                  ä¸»ãªå¤‰æ›´å†…å®¹                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  v12.0  â”‚ 2025-06-01 â”‚ ã‚·ã‚¹ãƒ†ãƒ  â”‚ è¤‡æ•°ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ±åˆãƒ»ã‚«ãƒ©ãƒ¼å‡ºåŠ›ãƒ»è¨ºæ–­æ©Ÿèƒ½ãƒ»å®Œå…¨ç‰ˆ    â”‚
â”‚  v11.0  â”‚ 2025-06-01 â”‚ ã‚·ã‚¹ãƒ†ãƒ  â”‚ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ãƒ»ãƒ­ã‚°å‡ºåŠ›æ”¹å–„ãƒ»è¨ºæ–­æ©Ÿèƒ½è¿½åŠ   â”‚
â”‚  v10.0  â”‚ 2025-06-01 â”‚ ã‚·ã‚¹ãƒ†ãƒ  â”‚ è¤‡æ•°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®çµ±åˆãƒ»å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«åŒ–ãƒ»æ©Ÿèƒ½çµ±ä¸€      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

çµ±åˆå†…å®¹:
- create_table_definitions.py (v10.0) - åŸºæœ¬æ©Ÿèƒ½ãƒ»mainé–¢æ•°
- create_table_definitions_enhanced.py (v11.0) - ã‚«ãƒ©ãƒ¼å‡ºåŠ›ãƒ»è¨ºæ–­æ©Ÿèƒ½
- create_table_definitions_enhanced_complete.py (v11.0) - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
â†’ å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«å®Œå…¨çµ±åˆã—ã€ä¿å®ˆæ€§ã¨é‹ç”¨åŠ¹ç‡ã‚’æœ€å¤§åŒ–

æ–°æ©Ÿèƒ½:
- ã‚«ãƒ©ãƒ¼å‡ºåŠ›å¯¾å¿œï¼ˆæˆåŠŸ=ç·‘ã€è­¦å‘Š=é»„ã€ã‚¨ãƒ©ãƒ¼=èµ¤ï¼‰
- è©³ç´°è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½
- ä¸è¶³YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
- å®Ÿè¡Œå‰æ¤œè¨¼æ©Ÿèƒ½ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰
- ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šã®é›†ç´„ã‚µãƒãƒªãƒ¼è¡¨ç¤º
- é€²æ—è¡¨ç¤ºã®æ”¹å–„
"""

import os
import re
import sys
import yaml
import json
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›ç”¨ï¼ˆcoloramaãŒãªã„å ´åˆã®ä»£æ›¿ï¼‰
class Colors:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

class LogLevel(Enum):
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    SUCCESS = "SUCCESS"

@dataclass
class ProcessingResult:
    """å‡¦ç†çµæœã‚’æ ¼ç´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    table_name: str
    logical_name: str
    success: bool
    has_yaml: bool
    error_message: Optional[str] = None
    warning_message: Optional[str] = None

class EnhancedLogger:
    """å¼·åŒ–ã•ã‚ŒãŸãƒ­ã‚°å‡ºåŠ›ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, enable_color: bool = True):
        self.enable_color = enable_color
        self.logs = []
    
    def _colorize(self, text: str, color: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã«è‰²ã‚’ä»˜ã‘ã‚‹"""
        if not self.enable_color:
            return text
        return f"{color}{text}{Colors.END}"
    
    def info(self, message: str):
        """æƒ…å ±ãƒ­ã‚°"""
        colored_msg = self._colorize(f"â„¹ï¸  {message}", Colors.BLUE)
        print(colored_msg)
        self.logs.append((LogLevel.INFO, message))
    
    def warning(self, message: str):
        """è­¦å‘Šãƒ­ã‚°"""
        colored_msg = self._colorize(f"âš ï¸  {message}", Colors.YELLOW)
        print(colored_msg)
        self.logs.append((LogLevel.WARNING, message))
    
    def error(self, message: str):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"""
        colored_msg = self._colorize(f"âŒ {message}", Colors.RED)
        print(colored_msg)
        self.logs.append((LogLevel.ERROR, message))
    
    def success(self, message: str):
        """æˆåŠŸãƒ­ã‚°"""
        colored_msg = self._colorize(f"âœ… {message}", Colors.GREEN)
        print(colored_msg)
        self.logs.append((LogLevel.SUCCESS, message))
    
    def header(self, message: str):
        """ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ­ã‚°"""
        colored_msg = self._colorize(f"\nğŸš€ {message}", Colors.CYAN + Colors.BOLD)
        print(colored_msg)
        print(self._colorize("=" * 80, Colors.CYAN))
    
    def section(self, message: str):
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ­ã‚°"""
        colored_msg = self._colorize(f"\nğŸ“‹ {message}", Colors.MAGENTA + Colors.BOLD)
        print(colored_msg)
        print(self._colorize("-" * 60, Colors.MAGENTA))

class TableDefinitionGenerator:
    """ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚¯ãƒ©ã‚¹ï¼ˆçµ±åˆç‰ˆï¼‰"""
    
    def __init__(self, base_dir: str = None, enable_color: bool = True):
        """åˆæœŸåŒ–"""
        self.base_dir = Path(base_dir) if base_dir else Path(__file__).parent
        self.tables_dir = self.base_dir / "tables"
        self.ddl_dir = self.base_dir / "ddl"
        self.details_dir = self.base_dir / "table-details"
        self.table_list_file = self.base_dir / "ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§.md"
        
        # ãƒ­ã‚°è¨­å®š
        self.logger = EnhancedLogger(enable_color)
        
        # å‡¦ç†çµæœè¿½è·¡
        self.results: List[ProcessingResult] = []
        self.missing_yamls: List[str] = []
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self._ensure_directories()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
        self.tables_info = {}
        self.common_columns = self._get_common_columns()
    
    def _ensure_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        try:
            self.tables_dir.mkdir(exist_ok=True)
            self.ddl_dir.mkdir(exist_ok=True)
            self.details_dir.mkdir(exist_ok=True)
        except Exception as e:
            self.logger.error(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            raise
        
    def _get_common_columns(self) -> Dict[str, Any]:
        """å…±é€šã‚«ãƒ©ãƒ å®šç¾©ã‚’å–å¾—"""
        return {
            'audit_columns': [
                {
                    'name': 'created_at',
                    'logical': 'ä½œæˆæ—¥æ™‚',
                    'type': 'TIMESTAMP',
                    'length': None,
                    'null': False,
                    'default': 'CURRENT_TIMESTAMP',
                    'description': 'ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆæ—¥æ™‚'
                },
                {
                    'name': 'updated_at',
                    'logical': 'æ›´æ–°æ—¥æ™‚',
                    'type': 'TIMESTAMP',
                    'length': None,
                    'null': False,
                    'default': 'CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP',
                    'description': 'ãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°æ—¥æ™‚'
                },
                {
                    'name': 'created_by',
                    'logical': 'ä½œæˆè€…',
                    'type': 'VARCHAR',
                    'length': 50,
                    'null': False,
                    'description': 'ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆè€…ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ID'
                },
                {
                    'name': 'updated_by',
                    'logical': 'æ›´æ–°è€…',
                    'type': 'VARCHAR',
                    'length': 50,
                    'null': False,
                    'description': 'ãƒ¬ã‚³ãƒ¼ãƒ‰æ›´æ–°è€…ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ID'
                }
            ],
            'tenant_columns': [
                {
                    'name': 'tenant_id',
                    'logical': 'ãƒ†ãƒŠãƒ³ãƒˆID',
                    'type': 'VARCHAR',
                    'length': 50,
                    'null': False,
                    'description': 'ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆè­˜åˆ¥å­'
                }
            ],
            'base_columns': [
                {
                    'name': 'id',
                    'logical': 'ID',
                    'type': 'VARCHAR',
                    'length': 50,
                    'null': False,
                    'primary': True,
                    'description': 'ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼ï¼ˆUUIDï¼‰'
                },
                {
                    'name': 'is_deleted',
                    'logical': 'å‰Šé™¤ãƒ•ãƒ©ã‚°',
                    'type': 'BOOLEAN',
                    'length': None,
                    'null': False,
                    'default': False,
                    'description': 'è«–ç†å‰Šé™¤ãƒ•ãƒ©ã‚°'
                }
            ]
        }
    
    def load_table_list(self) -> Dict[str, Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§.mdã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
        if not self.table_list_file.exists():
            raise FileNotFoundError(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.table_list_file}")
        
        with open(self.table_list_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’æŠ½å‡ºï¼ˆæ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å½¢å¼ã«å¯¾å¿œï¼‰
        tables = {}
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        lines = content.split('\n')
        in_table = False
        
        for line in lines:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ¤œå‡º
            if '| ãƒ†ãƒ¼ãƒ–ãƒ«ID |' in line and 'ãƒ†ãƒ¼ãƒ–ãƒ«å' in line:
                in_table = True
                continue
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«åŒºåˆ‡ã‚Šè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            if in_table and line.startswith('|---'):
                continue
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«çµ‚äº†ã‚’æ¤œå‡º
            if in_table and (line.strip() == '' or not line.startswith('|')):
                in_table = False
                continue
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’è§£æ
            if in_table and line.startswith('| TBL-'):
                parts = [part.strip() for part in line.split('|')]
                if len(parts) >= 5:
                    table_id = parts[1]
                    category = parts[2]
                    table_name = parts[3]
                    logical_name = parts[4]
                    
                    tables[table_name] = {
                        'table_id': table_id,
                        'category': category,
                        'logical_name': logical_name,
                        'table_name': table_name
                    }
        
        return tables
    
    def load_table_details(self, table_name: str) -> Tuple[Optional[Dict[str, Any]], bool]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°å®šç¾©YAMLã‚’èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ãƒ•ãƒ©ã‚°ã‚‚è¿”ã™ï¼‰"""
        details_file = self.details_dir / f"{table_name}_details.yaml"
        
        if not details_file.exists():
            return None, False
        
        try:
            with open(details_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f), True
        except Exception as e:
            self.logger.error(f"{details_file} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return None, False
    
    def generate_ddl(self, table_name: str, table_info: Dict[str, Any]) -> Tuple[str, bool]:
        """DDLã‚’ç”Ÿæˆï¼ˆYAMLãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒ•ãƒ©ã‚°ã‚‚è¿”ã™ï¼‰"""
        details, has_yaml = self.load_table_details(table_name)
        
        ddl_content = f"-- {table_name} ({table_info['logical_name']}) DDL\n"
        ddl_content += f"-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        if not has_yaml:
            ddl_content += "-- æ³¨æ„: è©³ç´°YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€åŸºæœ¬å®šç¾©ã®ã¿ã§ç”Ÿæˆ\n"
        ddl_content += "\n"
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        ddl_content += f"CREATE TABLE {table_name} (\n"
        
        columns = []
        
        # åŸºæœ¬ã‚«ãƒ©ãƒ 
        for col in self.common_columns['base_columns']:
            col_type = col['type']
            if col.get('length'):
                col_type += f"({col['length']})"
            
            col_def = f"    {col['name']} {col_type}"
            if not col.get('null', True):
                col_def += " NOT NULL"
            if col.get('default') is not None:
                if isinstance(col['default'], str):
                    col_def += f" DEFAULT '{col['default']}'"
                else:
                    col_def += f" DEFAULT {col['default']}"
            if col.get('primary'):
                col_def += " PRIMARY KEY"
            columns.append(col_def)
        
        # ãƒ†ãƒŠãƒ³ãƒˆã‚«ãƒ©ãƒ 
        if not table_name.startswith('SYS_'):
            for col in self.common_columns['tenant_columns']:
                col_type = col['type']
                if col.get('length'):
                    col_type += f"({col['length']})"
                
                col_def = f"    {col['name']} {col_type}"
                if not col.get('null', True):
                    col_def += " NOT NULL"
                columns.append(col_def)
        
        # æ¥­å‹™å›ºæœ‰ã‚«ãƒ©ãƒ 
        if details and 'business_columns' in details:
            for col in details['business_columns']:
                col_type = col['type']
                if col.get('length'):
                    col_type += f"({col['length']})"
                
                col_def = f"    {col['name']} {col_type}"
                if not col.get('null', True):
                    col_def += " NOT NULL"
                if col.get('default') is not None:
                    if isinstance(col['default'], str):
                        col_def += f" DEFAULT '{col['default']}'"
                    else:
                        col_def += f" DEFAULT {col['default']}"
                columns.append(col_def)
        
        # ç›£æŸ»ã‚«ãƒ©ãƒ 
        for col in self.common_columns['audit_columns']:
            col_type = col['type']
            if col.get('length'):
                col_type += f"({col['length']})"
            
            col_def = f"    {col['name']} {col_type}"
            if not col.get('null', True):
                col_def += " NOT NULL"
            if col.get('default'):
                col_def += f" DEFAULT {col['default']}"
            columns.append(col_def)
        
        ddl_content += ",\n".join(columns)
        ddl_content += "\n);\n\n"
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        if details and 'business_indexes' in details:
            for idx in details['business_indexes']:
                unique_str = "UNIQUE " if idx.get('unique', False) else ""
                columns_str = ", ".join(idx['columns'])
                ddl_content += f"CREATE {unique_str}INDEX {idx['name']} ON {table_name} ({columns_str});\n"
        
        # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„
        if details and 'foreign_keys' in details:
            ddl_content += "\n-- å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„\n"
            for fk in details['foreign_keys']:
                ddl_content += f"ALTER TABLE {table_name} ADD CONSTRAINT {fk['name']} "
                ddl_content += f"FOREIGN KEY ({fk['column']}) REFERENCES {fk['reference_table']}({fk['reference_column']}) "
                ddl_content += f"ON UPDATE {fk['on_update']} ON DELETE {fk['on_delete']};\n"
        
        return ddl_content, has_yaml
    
    def generate_files(self, table_names: List[str] = None, output_dir: str = None, dry_run: bool = False):
        """ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆçµ±åˆç‰ˆï¼‰"""
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§èª­ã¿è¾¼ã¿
        self.tables_info = self.load_table_list()
        
        # å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        if output_dir:
            output_path = Path(output_dir)
            tables_output = output_path / "tables"
            ddl_output = output_path / "ddl"
            tables_output.mkdir(parents=True, exist_ok=True)
            ddl_output.mkdir(parents=True, exist_ok=True)
        else:
            tables_output = self.tables_dir
            ddl_output = self.ddl_dir
        
        # å‡¦ç†å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«æ±ºå®š
        if table_names:
            target_tables = {name: info for name, info in self.tables_info.items() if name in table_names}
            missing_tables = set(table_names) - set(self.tables_info.keys())
            if missing_tables:
                self.logger.warning(f"ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_tables)}")
        else:
            target_tables = self.tables_info
        
        self.logger.header(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ v12.0 (å®Œå…¨çµ±åˆç‰ˆ)")
        self.logger.info(f"{len(target_tables)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
        
        if dry_run:
            self.logger.warning("ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚¡ã‚¤ãƒ«ã¯å®Ÿéš›ã«ã¯ä½œæˆã•ã‚Œã¾ã›ã‚“")
        
        generated_ddls = []
        
        for table_name, table_info in target_tables.items():
            self.logger.info(f"å‡¦ç†ä¸­: {table_name} ({table_info['logical_name']})")
            
            try:
                # DDLç”Ÿæˆ
                ddl_content, has_yaml = self.generate_ddl(table_name, table_info)
                ddl_file = ddl_output / f"{table_name}.sql"
                
                if not dry_run:
                    with open(ddl_file, 'w', encoding='utf-8') as f:
                        f.write(ddl_content)
                    self.logger.success(f"  âœ“ {ddl_file}")
                else:
                    self.logger.info(f"  [DRY] {ddl_file}")
                
                generated_ddls.append(ddl_content)
                
                # å‡¦ç†çµæœã‚’è¨˜éŒ²
                result = ProcessingResult(
                    table_name=table_name,
                    logical_name=table_info['logical_name'],
                    success=True,
                    has_yaml=has_yaml
                )
                if not has_yaml:
                    result.warning_message = "YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“"
                self.results.append(result)
                
            except Exception as e:
                error_msg = f"ã‚¨ãƒ©ãƒ¼: {e}"
                self.logger.error(f"  âŒ {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼çµæœã‚’è¨˜éŒ²
                result = ProcessingResult(
                    table_name=table_name,
                    logical_name=table_info['logical_name'],
                    success=False,
                    has_yaml=False,
                    error_message=str(e)
                )
                self.results.append(result)
        
        # çµ±åˆDDLç”Ÿæˆ
        if generated_ddls and not dry_run:
            all_ddl_file = ddl_output / "all_tables.sql"
            with open(all_ddl_file, 'w', encoding='utf-8') as f:
                f.write("-- å…¨ãƒ†ãƒ¼ãƒ–ãƒ«çµ±åˆDDL\n")
                f.write(f"-- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("\n\n".join(generated_ddls))
            self.logger.success(f"çµ±åˆDDL: {all_ddl_file}")
        elif generated_ddls and dry_run:
            self.logger.info(f"[DRY] çµ±åˆDDL: {ddl_output / 'all_tables.sql'}")
        
        # å‡¦ç†çµæœã‚µãƒãƒªãƒ¼
        self._print_summary()
        
        self.logger.success(f"å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        self.logger.info(f"ğŸ“ DDLå‡ºåŠ›å…ˆ: {ddl_output}")
    
    def _print_summary(self):
        """å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        self.logger.section("å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
        
        total = len(self.results)
        success = len([r for r in self.results if r.success])
        errors = len([r for r in self.results if not r.success])
        warnings = len([r for r in self.results if r.success and not r.has_yaml])
        
        self.logger.info(f"ç·ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {total}")
        self.logger.success(f"æˆåŠŸ: {success}")
        if errors > 0:
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼: {errors}")
        if warnings > 0:
            self.logger.warning(f"è­¦å‘Š: {warnings} (YAMLãƒ•ã‚¡ã‚¤ãƒ«ä¸è¶³)")
        
        # ã‚¨ãƒ©ãƒ¼è©³ç´°
        if errors > 0:
            self.logger.section("ã‚¨ãƒ©ãƒ¼è©³ç´°")
            for result in self.results:
                if not result.success:
                    self.logger.error(f"{result.table_name}: {result.error_message}")
        
        # è­¦å‘Šè©³ç´°
        if warnings > 0:
            self.logger.section("è­¦å‘Šè©³ç´° (YAMLãƒ•ã‚¡ã‚¤ãƒ«ä¸è¶³)")
            for result in self.results:
                if result.success and not result.has_yaml:
                    self.logger.warning(f"{result.table_name}: åŸºæœ¬å®šç¾©ã®ã¿ã§ç”Ÿæˆ")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ v12.0 (å®Œå…¨çµ±åˆç‰ˆ)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
  python3 create_table_definitions.py
  
  # å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
  python3 create_table_definitions.py --table MST_Employee
  python3 create_table_definitions.py --table MST_Role,MST_Permission
  
  # å‡ºåŠ›å…ˆæŒ‡å®š
  python3 create_table_definitions.py --table MST_Employee --output-dir custom/
  
  # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
  python3 create_table_definitions.py --dry-run
        """
    )
    
    parser.add_argument(
        '--table', '-t',
        help='ç”Ÿæˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«åï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¤‡æ•°æŒ‡å®šå¯èƒ½ï¼‰'
    )
    
    parser.add_argument(
        '--output-dir', '-o',
        help='å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
    )
    
    parser.add_argument(
        '--base-dir', '-b',
        help='ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿéš›ã«ã¯ä½œæˆã—ãªã„ï¼‰'
    )
    
    parser.add_argument(
        '--no-color',
        action='store_true',
        help='ã‚«ãƒ©ãƒ¼å‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–'
    )
    
    args = parser.parse_args()
    
    try:
        generator = TableDefinitionGenerator(args.base_dir, not args.no_color)
        
        # å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«æ±ºå®š
        target_tables = None
        
        if args.table:
            target_tables = [t.strip() for t in args.table.split(',')]
        
        generator.generate_files(target_tables, args.output_dir, args.dry_run)
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
