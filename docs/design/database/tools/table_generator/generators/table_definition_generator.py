#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Markdownå½¢å¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã¨DDLã‚’ç”Ÿæˆã™ã‚‹
ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from table_generator.core.logger import EnhancedLogger
from table_generator.core.config import Config
from table_generator.core.models import TableDefinition, ProcessingResult
from table_generator.utils.yaml_loader import YamlLoader
from table_generator.utils.file_utils import FileUtils
from table_generator.utils.sql_utils import SqlUtils
from table_generator.generators.common_columns import CommonColumns
from table_generator.generators.ddl_generator import DDLGenerator
from table_generator.data.faker_utils import FakerUtils


class TableDefinitionGenerator:
    """ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’èª­ã¿è¾¼ã¿ã€Markdownå½¢å¼ã®å®šç¾©æ›¸ã¨
    DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹çµ±åˆå‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚
    """
    
    def __init__(self, base_dir: str = None, logger: EnhancedLogger = None):
        """åˆæœŸåŒ–
        
        Args:
            base_dir (str, optional): ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            logger (EnhancedLogger, optional): ãƒ­ã‚°å‡ºåŠ›ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.config = Config(base_dir=base_dir)
        self.logger = logger or EnhancedLogger()
        self.yaml_loader = YamlLoader(logger=self.logger)
        self.file_utils = FileUtils(logger=self.logger)
        self.sql_utils = SqlUtils(logger=self.logger)
        self.ddl_generator = DDLGenerator(logger=self.logger)
        self.faker_utils = FakerUtils(logger=self.logger)
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.config.ensure_directories()
        
        self.logger.info("TableDefinitionGenerator ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def generate_files(self, table_names: Optional[List[str]] = None, 
                      output_dir: Optional[str] = None, 
                      dry_run: bool = False) -> ProcessingResult:
        """ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã¨DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            table_names (List[str], optional): ç”Ÿæˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
            
        Returns:
            ProcessingResult: å‡¦ç†çµæœ
        """
        result = ProcessingResult()
        
        try:
            self.logger.header("ğŸš€ ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
            table_list = self._get_table_list(table_names)
            if not table_list:
                self.logger.error("ç”Ÿæˆå¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                result.success = False
                result.error_message = "ç”Ÿæˆå¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                return result
            
            self.logger.info(f"ğŸ“‹ ç”Ÿæˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(table_list)}")
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
            for table_name, table_info in table_list.items():
                self.logger.section(f"ğŸ“ {table_name} ã®å‡¦ç†ã‚’é–‹å§‹")
                
                try:
                    # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’ç”Ÿæˆ
                    table_result = self._process_table(
                        table_name, table_info, output_dir, dry_run
                    )
                    
                    if table_result.success:
                        result.processed_files.extend(table_result.processed_files)
                        result.generated_files.extend(table_result.generated_files)
                        self.logger.success(f"âœ… {table_name} ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        result.errors.append(f"{table_name}: {table_result.error_message}")
                        self.logger.error(f"âŒ {table_name} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {table_result.error_message}")
                        
                except Exception as e:
                    error_msg = f"{table_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
                    result.errors.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
            
            # çµæœã‚µãƒãƒªãƒ¼
            result.success = len(result.errors) == 0
            self._log_summary(result, dry_run)
            
        except Exception as e:
            result.success = False
            result.error_message = f"ç”Ÿæˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            self.logger.error(f"âŒ {result.error_message}")
        
        return result
    
    def _get_table_list(self, table_names: Optional[List[str]] = None) -> Dict[str, Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
        
        Args:
            table_names (List[str], optional): æŒ‡å®šãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ
            
        Returns:
            Dict[str, Dict[str, Any]]: ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§è¾æ›¸
        """
        try:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§.mdã‹ã‚‰èª­ã¿è¾¼ã¿
            table_list_file = self.config.get_table_list_file()
            if not table_list_file.exists():
                self.logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_list_file}")
                return {}
            
            all_tables = self.yaml_loader.get_table_list_from_markdown(table_list_file)
            
            # æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if table_names:
                filtered_tables = {}
                for table_name in table_names:
                    if table_name in all_tables:
                        filtered_tables[table_name] = all_tables[table_name]
                    else:
                        self.logger.warning(f"æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_name}")
                return filtered_tables
            
            return all_tables
            
        except Exception as e:
            self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    def _process_table(self, table_name: str, table_info: Dict[str, Any], 
                      output_dir: Optional[str], dry_run: bool) -> ProcessingResult:
        """å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            table_info (Dict[str, Any]): ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
            
        Returns:
            ProcessingResult: å‡¦ç†çµæœ
        """
        result = ProcessingResult()
        
        try:
            # YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            yaml_file = self.config.get_details_dir() / f"{table_name}.yaml"
            if not yaml_file.exists():
                result.success = False
                result.error_message = f"YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}"
                return result
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’è§£æ
            yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
            if not yaml_data:
                result.success = False
                result.error_message = f"YAMLå®šç¾©ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {yaml_file}"
                return result
            
            table_def = self.yaml_loader.parse_table_definition(yaml_data)
            if not table_def:
                result.success = False
                result.error_message = f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®è§£æã«å¤±æ•—: {table_name}"
                return result
            
            # å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            self._add_common_columns(table_def)
            
            # Markdownå®šç¾©æ›¸ã‚’ç”Ÿæˆ
            markdown_content = self._generate_markdown_definition(table_def, table_info)
            
            # DDLã‚’ç”Ÿæˆ
            ddl_content = self.ddl_generator.generate_table_ddl(table_def)
            
            if not dry_run:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
                self._write_output_files(table_name, markdown_content, ddl_content, output_dir, result)
            else:
                self.logger.info(f"ğŸ” [DRY RUN] {table_name} ã®å‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                result.generated_files.append(f"[DRY RUN] {table_name}.md")
                result.generated_files.append(f"[DRY RUN] {table_name}.sql")
            
            result.success = True
            
        except Exception as e:
            result.success = False
            result.error_message = str(e)
        
        return result
    
    def _add_common_columns(self, table_def: TableDefinition):
        """å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        
        Args:
            table_def (TableDefinition): ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
        """
        # ãƒ†ãƒ¼ãƒ–ãƒ«ç¨®åˆ¥ã«å¿œã˜ã¦å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        if table_def.table_name.startswith('MST_'):
            # ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            common_cols = CommonColumns.get_master_table_columns()
        elif table_def.table_name.startswith('TRN_'):
            # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            common_cols = CommonColumns.get_all_common_columns(table_def.table_name)
        else:
            # ãã®ä»–
            common_cols = CommonColumns.get_base_columns()
        
        # æ—¢å­˜ã‚«ãƒ©ãƒ ã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«è¿½åŠ 
        existing_names = {col.name for col in table_def.business_columns}
        for common_col in common_cols:
            if common_col.name not in existing_names:
                table_def.business_columns.append(common_col)
    
    def _generate_markdown_definition(self, table_def: TableDefinition, 
                                    table_info: Dict[str, Any]) -> str:
        """Markdownå½¢å¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã‚’ç”Ÿæˆ
        
        Args:
            table_def (TableDefinition): ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
            table_info (Dict[str, Any]): ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
            
        Returns:
            str: Markdownå½¢å¼ã®å®šç¾©æ›¸
        """
        lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        lines.append(f"# {table_def.table_name}")
        lines.append("")
        lines.append(f"**{table_def.logical_name}**")
        lines.append("")
        lines.append(f"**æ¦‚è¦**: {table_def.description}")
        lines.append("")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
        lines.append("## ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±")
        lines.append("")
        lines.append("| é …ç›® | å€¤ |")
        lines.append("|------|-----|")
        lines.append(f"| ãƒ†ãƒ¼ãƒ–ãƒ«å | {table_def.table_name} |")
        lines.append(f"| è«–ç†å | {table_def.logical_name} |")
        lines.append(f"| èª¬æ˜ | {table_def.description} |")
        lines.append(f"| ä½œæˆæ—¥ | {datetime.now().strftime('%Y-%m-%d')} |")
        lines.append("")
        
        # ã‚«ãƒ©ãƒ å®šç¾©
        lines.append("## ã‚«ãƒ©ãƒ å®šç¾©")
        lines.append("")
        lines.append("| No | ã‚«ãƒ©ãƒ å | ãƒ‡ãƒ¼ã‚¿å‹ | NULL | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |")
        lines.append("|----|----------|----------|------|------------|------|")
        
        for i, col in enumerate(table_def.business_columns, 1):
            null_str = "â—‹" if col.null else "Ã—"
            default_str = str(col.default) if col.default is not None else ""
            lines.append(f"| {i} | {col.name} | {col.data_type} | {null_str} | {default_str} | {col.description} |")
        
        lines.append("")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©
        if table_def.business_indexes:
            lines.append("## ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©")
            lines.append("")
            lines.append("| ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å | ã‚«ãƒ©ãƒ  | ãƒ¦ãƒ‹ãƒ¼ã‚¯ | èª¬æ˜ |")
            lines.append("|----------------|--------|----------|------|")
            
            for idx in table_def.business_indexes:
                unique_str = "â—‹" if idx.unique else "Ã—"
                columns_str = ", ".join(idx.columns)
                lines.append(f"| {idx.name} | {columns_str} | {unique_str} | {idx.description} |")
            
            lines.append("")
        
        # å¤–éƒ¨ã‚­ãƒ¼å®šç¾©
        if table_def.foreign_keys:
            lines.append("## å¤–éƒ¨ã‚­ãƒ¼å®šç¾©")
            lines.append("")
            lines.append("| åˆ¶ç´„å | ã‚«ãƒ©ãƒ  | å‚ç…§ãƒ†ãƒ¼ãƒ–ãƒ« | å‚ç…§ã‚«ãƒ©ãƒ  | èª¬æ˜ |")
            lines.append("|--------|--------|--------------|------------|------|")
            
            for fk in table_def.foreign_keys:
                lines.append(f"| {fk.name} | {fk.column} | {fk.reference_table} | {fk.reference_column} | {fk.description} |")
            
            lines.append("")
        
        # ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«
        if table_def.business_rules:
            lines.append("## ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«")
            lines.append("")
            for i, rule in enumerate(table_def.business_rules, 1):
                lines.append(f"{i}. {rule}")
            lines.append("")
        
        # å‚™è€ƒ
        if table_def.notes:
            lines.append("## å‚™è€ƒ")
            lines.append("")
            for note in table_def.notes:
                lines.append(f"- {note}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _write_output_files(self, table_name: str, markdown_content: str, 
                           ddl_content: str, output_dir: Optional[str], 
                           result: ProcessingResult):
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            markdown_content (str): Markdownå†…å®¹
            ddl_content (str): DDLå†…å®¹
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            result (ProcessingResult): å‡¦ç†çµæœ
        """
        try:
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
            if output_dir:
                tables_dir = Path(output_dir) / "tables"
                ddl_dir = Path(output_dir) / "ddl"
            else:
                tables_dir = self.config.get_tables_dir()
                ddl_dir = self.config.get_ddl_dir()
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            self.file_utils.ensure_directories([tables_dir, ddl_dir])
            
            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            md_file = tables_dir / f"{table_name}.md"
            if self.file_utils.write_file(md_file, markdown_content):
                result.generated_files.append(str(md_file))
                self.logger.info(f"ğŸ“„ Markdownå®šç¾©æ›¸ã‚’å‡ºåŠ›: {md_file}")
            
            # DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            sql_file = ddl_dir / f"{table_name}.sql"
            if self.file_utils.write_file(sql_file, ddl_content):
                result.generated_files.append(str(sql_file))
                self.logger.info(f"ğŸ—ƒï¸ DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›: {sql_file}")
                
        except Exception as e:
            raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _log_summary(self, result: ProcessingResult, dry_run: bool):
        """å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›
        
        Args:
            result (ProcessingResult): å‡¦ç†çµæœ
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
        """
        self.logger.header("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
        
        if dry_run:
            self.logger.info("ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ")
        
        self.logger.info(f"ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(result.generated_files)}")
        self.logger.info(f"âš ï¸ ã‚¨ãƒ©ãƒ¼æ•°: {len(result.errors)}")
        
        if result.errors:
            self.logger.section("âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°")
            for error in result.errors:
                self.logger.error(f"  - {error}")
        
        if result.success:
            self.logger.success("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            self.logger.error("ğŸ’¥ ä¸€éƒ¨ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    
    def generate_sample_data(self, table_name: str, count: int = 10) -> List[Dict[str, Any]]:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            count (int): ç”Ÿæˆä»¶æ•°
            
        Returns:
            List[Dict[str, Any]]: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        try:
            # YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            yaml_file = self.config.get_details_dir() / f"{table_name}.yaml"
            if not yaml_file.exists():
                self.logger.error(f"YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}")
                return []
            
            yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
            table_def = self.yaml_loader.parse_table_definition(yaml_data)
            
            if not table_def:
                self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®è§£æã«å¤±æ•—: {table_name}")
                return []
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            sample_data = []
            for i in range(count):
                row_data = {}
                for col in table_def.business_columns:
                    # ã‚«ãƒ©ãƒ ã®å‹ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                    row_data[col.name] = self._generate_column_data(col, i)
                sample_data.append(row_data)
            
            return sample_data
            
        except Exception as e:
            self.logger.error(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _generate_column_data(self, column, index: int):
        """ã‚«ãƒ©ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            column: ã‚«ãƒ©ãƒ å®šç¾©
            index (int): ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns:
            Any: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        # ãƒ‡ãƒ¼ã‚¿å‹ã«å¿œã˜ã¦ç”Ÿæˆ
        if column.data_type.upper().startswith('VARCHAR'):
            return self.faker_utils.generate_by_type('text')
        elif column.data_type.upper().startswith('INT'):
            return index + 1
        elif column.data_type.upper().startswith('DATE'):
            return self.faker_utils.generate_by_type('date')
        elif column.data_type.upper().startswith('TIMESTAMP'):
            return self.faker_utils.generate_by_type('datetime')
        else:
            return f"sample_{index}"
