#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Markdownå½¢å¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã¨DDLã‚’ç”Ÿæˆã™ã‚‹
ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from shared.core.logger import DatabaseToolsLogger, get_logger
from shared.core.config import DatabaseToolsConfig
from shared.core.models import TableDefinition, GenerationResult, ProcessingResult, BusinessColumnDefinition
from table_generator.utils.yaml_loader import YamlLoader
from table_generator.utils.file_utils import FileUtils
from table_generator.utils.sql_utils import SqlUtils
from table_generator.generators.common_columns import CommonColumns
from table_generator.generators.ddl_generator import DDLGenerator
from table_generator.generators.insert_generator import InsertGenerator
from table_generator.data.faker_utils import FakerUtils


class TableDefinitionGenerator:
    """ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
    
    YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’èª­ã¿è¾¼ã¿ã€Markdownå½¢å¼ã®å®šç¾©æ›¸ã¨
    DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹çµ±åˆå‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚
    """
    
    def __init__(self, base_dir: str = None, logger: DatabaseToolsLogger = None):
        """åˆæœŸåŒ–
        
        Args:
            base_dir (str, optional): ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            logger (DatabaseToolsLogger, optional): ãƒ­ã‚°å‡ºåŠ›ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        # base_dirã‚’Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        base_path = Path(base_dir) if base_dir else None
        self.config = DatabaseToolsConfig(base_dir=base_path)
        self.logger = logger or get_logger()
        self.yaml_loader = YamlLoader(logger=self.logger)
        self.file_utils = FileUtils(logger=self.logger)
        self.sql_utils = SqlUtils(logger=self.logger)
        self.ddl_generator = DDLGenerator(logger=self.logger)
        self.insert_generator = InsertGenerator(logger=self.logger)
        self.faker_utils = FakerUtils(logger=self.logger)
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.config._ensure_directories()
        
        self.logger.info("TableDefinitionGenerator ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def generate_files(self, table_names: Optional[List[str]] = None, 
                      output_dir: Optional[str] = None, 
                      dry_run: bool = False) -> GenerationResult:
        """ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã¨DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            table_names (List[str], optional): ç”Ÿæˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
            
        Returns:
            GenerationResult: å‡¦ç†çµæœ
        """
        result = GenerationResult(
            table_name="multiple_tables"
        )
        
        try:
            self.logger.info("ğŸš€ ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
            table_list = self._get_table_list(table_names)
            if not table_list:
                self.logger.error("ç”Ÿæˆå¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                result.success = False
                result.error_message = "ç”Ÿæˆå¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                return result
            
            self.logger.info(f"ğŸ“‹ ç”Ÿæˆå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(table_list)}")
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
            for table_name, table_info in table_list.items():
                self.logger.info(f"ğŸ“ {table_name} ã®å‡¦ç†ã‚’é–‹å§‹")
                
                try:
                    # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’ç”Ÿæˆ
                    table_result = self._process_table(
                        table_name, table_info, output_dir, dry_run
                    )
                    
                    if table_result.success:
                        result.processed_files.extend(table_result.processed_files)
                        result.generated_files.extend(table_result.generated_files)
                        self.logger.info(f"âœ… {table_name} ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    else:
                        result.errors.append(f"{table_name}: {table_result.error_message}")
                        self.logger.error(f"âŒ {table_name} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {table_result.error_message}")
                        
                except Exception as e:
                    error_msg = f"{table_name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
                    result.errors.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
            
            # çµæœã‚µãƒãƒªãƒ¼
            result.success = len(result.errors) == 0
            self._log_summary(result, dry_run)
            
        except Exception as e:
            result.success = False
            result.error_message = f"ç”Ÿæˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}"
            self.logger.error(f"âŒ {result.error_message}")
        
        return result
    
    def _get_table_list(self, table_names: Optional[List[str]] = None) -> Dict[str, Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
        
        Args:
            table_names (List[str], optional): æŒ‡å®šãƒ†ãƒ¼ãƒ–ãƒ«åãƒªã‚¹ãƒˆ
            
        Returns:
            Dict[str, Dict[str, Any]]: ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§è¾æ›¸
        """
        try:
            # æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹å ´åˆã¯ã€ç›´æ¥YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
            if table_names:
                filtered_tables = {}
                for table_name in table_names:
                    yaml_file = self.config.get_details_dir() / f"{table_name}_details.yaml"
                    if yaml_file.exists():
                        yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
                        if yaml_data:
                            filtered_tables[table_name] = {
                                'table_name': yaml_data.get('table_name', table_name),
                                'logical_name': yaml_data.get('logical_name', ''),
                                'category': yaml_data.get('category', ''),
                                'priority': yaml_data.get('priority', 'medium')
                            }
                        else:
                            self.logger.warning(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {yaml_file}")
                    else:
                        self.logger.warning(f"æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}")
                return filtered_tables
            
            # å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®å ´åˆã¯ã€table-detailsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å–å¾—
            all_tables = {}
            details_dir = self.config.get_details_dir()
            if details_dir.exists():
                for yaml_file in details_dir.glob("*_details.yaml"):
                    table_name = yaml_file.stem.replace("_details", "")
                    yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
                    if yaml_data:
                        all_tables[table_name] = {
                            'table_name': yaml_data.get('table_name', table_name),
                            'logical_name': yaml_data.get('logical_name', ''),
                            'category': yaml_data.get('category', ''),
                            'priority': yaml_data.get('priority', 'medium')
                        }
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§.mdã‹ã‚‰èª­ã¿è¾¼ã¿
            if not all_tables:
                table_list_file = self.config.get_table_list_file()
                if table_list_file.exists():
                    all_tables = self.yaml_loader.get_table_list_from_markdown(table_list_file)
                else:
                    self.logger.warning(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {table_list_file}")
            
            return all_tables
            
        except Exception as e:
            self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {}
    
    def _process_table(self, table_name: str, table_info: Dict[str, Any], 
                      output_dir: Optional[str], dry_run: bool) -> ProcessingResult:
        """å€‹åˆ¥ãƒ†ãƒ¼ãƒ–ãƒ«ã®å‡¦ç†
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            table_info (Dict[str, Any]): ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
            
        Returns:
            ProcessingResult: å‡¦ç†çµæœ
        """
        result = ProcessingResult(
            table_name=table_name,
            logical_name=table_info.get('logical_name', ''),
            success=True,
            has_yaml=False
        )
        
        try:
            # YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            yaml_file = self.config.get_details_dir() / f"{table_name}_details.yaml"
            if not yaml_file.exists():
                result.success = False
                result.error_message = f"YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}"
                return result
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’è§£æ
            yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
            if not yaml_data:
                result.success = False
                result.error_message = f"YAMLå®šç¾©ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {yaml_file}"
                return result
            
            table_def = self.yaml_loader.parse_table_definition(yaml_data)
            if not table_def:
                result.success = False
                result.error_message = f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®è§£æã«å¤±æ•—: {table_name}"
                return result
            
            # å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            self._add_common_columns(table_def)
            
            # Markdownå®šç¾©æ›¸ã‚’ç”Ÿæˆ
            markdown_content = self._generate_markdown_definition(table_def, table_info)
            
            # DDLã‚’ç”Ÿæˆ
            ddl_content = self.ddl_generator.generate_table_ddl(table_def)
            
            # INSERTæ–‡ã‚’ç”Ÿæˆ
            insert_content = self.insert_generator.generate_insert_sql(table_def)
            
            if not dry_run:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
                self._write_output_files(table_name, table_def, markdown_content, ddl_content, insert_content, output_dir, result)
            else:
                self.logger.info(f"ğŸ” [DRY RUN] {table_name} ã®å‡ºåŠ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
                result.generated_files.append(f"[DRY RUN] {table_name}.md")
                result.generated_files.append(f"[DRY RUN] {table_name}.sql")
                result.generated_files.append(f"[DRY RUN] {table_name}_sample_data.sql")
            
            result.success = True
            
        except Exception as e:
            result.success = False
            result.error_message = str(e)
        
        return result
    
    def _add_common_columns(self, table_def: TableDefinition):
        """å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        
        Args:
            table_def (TableDefinition): ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
        """
        # ãƒ†ãƒ¼ãƒ–ãƒ«ç¨®åˆ¥ã«å¿œã˜ã¦å…±é€šã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
        if table_def.name.startswith('MST_'):
            # ãƒã‚¹ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            common_cols = CommonColumns.get_master_table_columns()
        elif table_def.name.startswith('TRN_'):
            # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            common_cols = CommonColumns.get_all_common_columns(table_def.name)
        else:
            # ãã®ä»–
            common_cols = CommonColumns.get_base_columns()
        
        # æ—¢å­˜ã‚«ãƒ©ãƒ ã¨é‡è¤‡ã—ãªã„ã‚ˆã†ã«è¿½åŠ 
        existing_names = {col.name for col in table_def.business_columns}
        for common_col in common_cols:
            if common_col.name not in existing_names:
                table_def.business_columns.append(common_col)
    
    def _generate_markdown_definition(self, table_def: TableDefinition, 
                                    table_info: Dict[str, Any]) -> str:
        """Markdownå½¢å¼ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ã‚’ç”Ÿæˆï¼ˆMST_Departmentå½¢å¼ï¼‰
        
        Args:
            table_def (TableDefinition): ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
            table_info (Dict[str, Any]): ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
            
        Returns:
            str: Markdownå½¢å¼ã®å®šç¾©æ›¸ï¼ˆMST_Departmentå½¢å¼ï¼‰
        """
        lines = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        logical_name = getattr(table_def, 'logical_name', table_def.name)
        lines.append(f"# ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸: {table_def.name}")
        lines.append("")
        
        # åŸºæœ¬æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
        lines.append("## åŸºæœ¬æƒ…å ±")
        lines.append("")
        lines.append("| é …ç›® | å€¤ |")
        lines.append("|------|-----|")
        lines.append(f"| ãƒ†ãƒ¼ãƒ–ãƒ«å | {table_def.name} |")
        lines.append(f"| è«–ç†å | {logical_name} |")
        
        category = getattr(table_def, 'category', 'ãƒã‚¹ã‚¿ç³»')
        lines.append(f"| ã‚«ãƒ†ã‚´ãƒª | {category} |")
        lines.append(f"| ç”Ÿæˆæ—¥æ™‚ | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} |")
        lines.append("")
        
        # æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        lines.append("## æ¦‚è¦")
        lines.append("")
        
        # æ¦‚è¦æ–‡ã‚’ç”Ÿæˆï¼ˆYAMLã®overviewãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
        if hasattr(table_def, 'overview') and table_def.overview:
            # YAMLã®overviewãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãã®ã¾ã¾å‡ºåŠ›
            overview_lines = table_def.overview.strip().split('\n')
            for line in overview_lines:
                if line.strip():  # ç©ºè¡Œã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                    lines.append(line.strip())
            lines.append("")
        else:
            # overviewãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            lines.append(f"{table_def.name}ï¼ˆ{logical_name}ï¼‰ã¯ã€{table_def.comment}")
            lines.append("")
            lines.append("ä¸»ãªç›®çš„ï¼š")
            lines.append(f"- {logical_name}ã®åŸºæœ¬æƒ…å ±ç®¡ç†")
            lines.append(f"- ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒ»ä¸€æ„æ€§ä¿è¨¼")
            lines.append(f"- é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºãƒ‡ãƒ¼ã‚¿æä¾›")
            lines.append("")
            lines.append(f"ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã€å¹´é–“ã‚¹ã‚­ãƒ«å ±å‘Šæ›¸ã‚·ã‚¹ãƒ†ãƒ ã®{category}ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€")
            lines.append("çµ„ç¹”é‹å–¶ã®æ§˜ã€…ãªæ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã®åŸºç›¤ã¨ãªã‚‹é‡è¦ãªãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚")
            lines.append("")
        
        lines.append("")
        
        # ã‚«ãƒ©ãƒ å®šç¾©ãƒ†ãƒ¼ãƒ–ãƒ«
        lines.append("## ã‚«ãƒ©ãƒ å®šç¾©")
        lines.append("")
        lines.append("| ã‚«ãƒ©ãƒ å | è«–ç†å | ãƒ‡ãƒ¼ã‚¿å‹ | é•·ã• | NULL | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |")
        lines.append("|----------|--------|----------|------|------|------------|------|")
        
        for col in table_def.business_columns:
            # ãƒ‡ãƒ¼ã‚¿å‹ã¨é•·ã•ã‚’åˆ†é›¢
            data_type = col.data_type
            length = ""
            if "(" in data_type and ")" in data_type:
                type_part = data_type.split("(")[0]
                length_part = data_type.split("(")[1].split(")")[0]
                data_type = type_part
                length = length_part
            
            # NULLè¨±å¯
            null_allowed = "â—‹" if col.nullable else "Ã—"
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            default_value = ""
            if col.default is not None:
                default_value = str(col.default)
            
            # è«–ç†åï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠ½å‡ºï¼‰
            logical_col_name = getattr(col, 'comment', col.name)
            if 'ï¼ˆ' in logical_col_name:
                logical_col_name = logical_col_name.split('ï¼ˆ')[0]
            
            lines.append(f"| {col.name} | {logical_col_name} | {data_type} | {length} | {null_allowed} | {default_value} | {getattr(col, 'comment', '')} |")
        
        lines.append("")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
        if table_def.business_indexes:
            lines.append("## ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
            lines.append("")
            lines.append("| ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å | ã‚«ãƒ©ãƒ  | ãƒ¦ãƒ‹ãƒ¼ã‚¯ | èª¬æ˜ |")
            lines.append("|----------------|--------|----------|------|")
            
            for idx in table_def.business_indexes:
                columns_str = ", ".join(idx.columns)
                unique_str = "â—‹" if idx.unique else "Ã—"
                lines.append(f"| {idx.name} | {columns_str} | {unique_str} | {idx.comment} |")
            
            lines.append("")
        
        # å¤–éƒ¨ã‚­ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
        if table_def.foreign_keys:
            lines.append("## å¤–éƒ¨ã‚­ãƒ¼")
            lines.append("")
            lines.append("| åˆ¶ç´„å | ã‚«ãƒ©ãƒ  | å‚ç…§ãƒ†ãƒ¼ãƒ–ãƒ« | å‚ç…§ã‚«ãƒ©ãƒ  | æ›´æ–°æ™‚ | å‰Šé™¤æ™‚ | èª¬æ˜ |")
            lines.append("|--------|--------|--------------|------------|--------|--------|------|")
            
            for fk in table_def.foreign_keys:
                on_update = getattr(fk, 'on_update', 'CASCADE')
                on_delete = getattr(fk, 'on_delete', 'RESTRICT')
                lines.append(f"| {fk.name} | {fk.column} | {fk.reference_table} | {fk.reference_column} | {on_update} | {on_delete} | {fk.comment} |")
            
            lines.append("")
        
        # åˆ¶ç´„ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒã‚§ãƒƒã‚¯åˆ¶ç´„ãªã©ï¼‰
        lines.append("## åˆ¶ç´„")
        lines.append("")
        lines.append("| åˆ¶ç´„å | ç¨®åˆ¥ | æ¡ä»¶ | èª¬æ˜ |")
        lines.append("|--------|------|------|------|")
        
        # ä¸»ã‚­ãƒ¼åˆ¶ç´„
        primary_cols = [col for col in table_def.business_columns if hasattr(col, 'primary') and col.primary]
        if primary_cols:
            pk_names = ", ".join([col.name for col in primary_cols])
            lines.append(f"| pk_{table_def.name.lower()} | PRIMARY KEY | {pk_names} | ä¸»ã‚­ãƒ¼åˆ¶ç´„ |")
        
        # ä¸€æ„åˆ¶ç´„
        unique_cols = [col for col in table_def.business_columns if hasattr(col, 'unique') and col.unique]
        for col in unique_cols:
            lines.append(f"| uk_{col.name} | UNIQUE |  | {col.name}ä¸€æ„åˆ¶ç´„ |")
        
        # ãã®ä»–ã®åˆ¶ç´„ï¼ˆä¾‹ï¼šãƒã‚§ãƒƒã‚¯åˆ¶ç´„ï¼‰
        for col in table_def.business_columns:
            if 'level' in col.name.lower() and 'INT' in col.data_type.upper():
                lines.append(f"| chk_{col.name} | CHECK | {col.name} > 0 | {col.name}æ­£å€¤ãƒã‚§ãƒƒã‚¯åˆ¶ç´„ |")
            elif 'status' in col.name.lower() or 'type' in col.name.lower():
                lines.append(f"| chk_{col.name} | CHECK | {col.name} IN (...) | {col.name}å€¤ãƒã‚§ãƒƒã‚¯åˆ¶ç´„ |")
        
        lines.append("")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        if hasattr(table_def, 'sample_data') and table_def.sample_data:
            lines.append("## ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
            lines.append("")
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ä½œæˆ
            sample_data = table_def.sample_data
            if sample_data:
                # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚«ãƒ©ãƒ åã‚’å–å¾—
                first_sample = sample_data[0]
                header_cols = list(first_sample.keys())
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼
                header_line = "| " + " | ".join(header_cols) + " |"
                lines.append(header_line)
                
                # ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿
                separator_line = "|" + "|".join(["------" for _ in header_cols]) + "|"
                lines.append(separator_line)
                
                # ãƒ‡ãƒ¼ã‚¿è¡Œï¼ˆæœ€å¤§3ä»¶ï¼‰
                for i, sample in enumerate(sample_data[:3]):
                    values = []
                    for col in header_cols:
                        value = sample.get(col, "")
                        if value is None:
                            value = "None"
                        values.append(str(value))
                    data_line = "| " + " | ".join(values) + " |"
                    lines.append(data_line)
            
            lines.append("")
        
        # ç‰¹è¨˜äº‹é …
        lines.append("## ç‰¹è¨˜äº‹é …")
        lines.append("")
        if hasattr(table_def, 'notes') and table_def.notes:
            for note in table_def.notes:
                lines.append(f"- {note}")
        else:
            lines.append("- ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒ»ä¸€æ„æ€§åˆ¶ç´„ã‚’é©åˆ‡ã«è¨­å®š")
            lines.append("- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ")
            lines.append("- é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºã‚’è€ƒæ…®ã—ãŸãƒ‡ãƒ¼ã‚¿æ§‹é€ ")
        lines.append("")
        
        # æ¥­å‹™ãƒ«ãƒ¼ãƒ«
        lines.append("## æ¥­å‹™ãƒ«ãƒ¼ãƒ«")
        lines.append("")
        if hasattr(table_def, 'business_rules') and table_def.business_rules:
            for rule in table_def.business_rules:
                lines.append(f"- {rule}")
        else:
            lines.append("- ä¸»ã‚­ãƒ¼ã®ä¸€æ„æ€§ã¯å¿…é ˆã§å¤‰æ›´ä¸å¯")
            lines.append("- å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã«ã‚ˆã‚‹å‚ç…§æ•´åˆæ€§ã®ä¿è¨¼")
            lines.append("- è«–ç†å‰Šé™¤ã«ã‚ˆã‚‹å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®ä¿æŒ")
        lines.append("")
        
        # æ”¹ç‰ˆå±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
        lines.append("## æ”¹ç‰ˆå±¥æ­´")
        lines.append("")
        lines.append("| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ›´æ–°æ—¥ | æ›´æ–°è€… | å¤‰æ›´å†…å®¹ |")
        lines.append("|------------|--------|--------|----------|")
        
        if hasattr(table_def, 'revision_history') and table_def.revision_history:
            for revision in table_def.revision_history:
                version = revision.get('version', '1.0.0')
                date = revision.get('date', datetime.now().strftime('%Y-%m-%d'))
                author = revision.get('author', 'é–‹ç™ºãƒãƒ¼ãƒ ')
                changes = revision.get('changes', 'ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©')
                lines.append(f"| {version} | {date} | {author} | {changes} |")
        else:
            lines.append(f"| 1.0.0 | {datetime.now().strftime('%Y-%m-%d')} | é–‹ç™ºãƒãƒ¼ãƒ  | åˆç‰ˆä½œæˆ - {logical_name}ãƒ†ãƒ¼ãƒ–ãƒ«ã®è©³ç´°å®šç¾© |")
        
        return "\n".join(lines)
    
    def _write_output_files(self, table_name: str, table_def: TableDefinition, 
                           markdown_content: str, ddl_content: str, insert_content: str,
                           output_dir: Optional[str], result: ProcessingResult):
        """å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            markdown_content (str): Markdownå†…å®¹
            ddl_content (str): DDLå†…å®¹
            output_dir (str, optional): å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            result (ProcessingResult): å‡¦ç†çµæœ
        """
        try:
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ±ºå®š
            if output_dir:
                tables_dir = Path(output_dir) / "tables"
                ddl_dir = Path(output_dir) / "ddl"
                data_dir = Path(output_dir) / "data"
            else:
                tables_dir = self.config.get_tables_dir()
                ddl_dir = self.config.get_ddl_dir()
                data_dir = self.config.data_dir
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            self.file_utils.ensure_directories([tables_dir, ddl_dir, data_dir])
            
            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›ï¼ˆè¦æ±‚ã•ã‚Œã¦ã„ã‚‹å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
            logical_name = getattr(table_def, 'logical_name', table_name)
            md_file = tables_dir / f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸_{table_name}_{logical_name}.md"
            if self.file_utils.write_file(md_file, markdown_content):
                result.generated_files.append(str(md_file))
                self.logger.info(f"ğŸ“„ Markdownå®šç¾©æ›¸ã‚’å‡ºåŠ›: {md_file}")
            
            # DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            sql_file = ddl_dir / f"{table_name}.sql"
            if self.file_utils.write_file(sql_file, ddl_content):
                result.generated_files.append(str(sql_file))
                self.logger.info(f"ğŸ—ƒï¸ DDLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›: {sql_file}")
            
            # INSERTæ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            insert_file = data_dir / f"{table_name}_sample_data.sql"
            if self.file_utils.write_file(insert_file, insert_content):
                result.generated_files.append(str(insert_file))
                self.logger.info(f"ğŸ“Š INSERTæ–‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›: {insert_file}")
                
        except Exception as e:
            raise Exception(f"ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _log_summary(self, result: ProcessingResult, dry_run: bool):
        """å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›
        
        Args:
            result (ProcessingResult): å‡¦ç†çµæœ
            dry_run (bool): ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°
        """
        self.logger.info("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
        
        if dry_run:
            self.logger.info("ğŸ” ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ")
        
        self.logger.info(f"ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(result.generated_files)}")
        self.logger.info(f"âš ï¸ ã‚¨ãƒ©ãƒ¼æ•°: {len(result.errors)}")
        
        if result.errors:
            self.logger.info("âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°")
            for error in result.errors:
                self.logger.error(f"  - {error}")
        
        if result.success:
            self.logger.info("ğŸ‰ ã™ã¹ã¦ã®å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            self.logger.error("ğŸ’¥ ä¸€éƒ¨ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
    
    def generate_sample_data(self, table_name: str, count: int = 10) -> List[Dict[str, Any]]:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            table_name (str): ãƒ†ãƒ¼ãƒ–ãƒ«å
            count (int): ç”Ÿæˆä»¶æ•°
            
        Returns:
            List[Dict[str, Any]]: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        try:
            # YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            yaml_file = self.config.get_details_dir() / f"{table_name}_details.yaml"
            if not yaml_file.exists():
                self.logger.error(f"YAMLå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}")
                return []
            
            yaml_data = self.yaml_loader.load_yaml_file(yaml_file)
            table_def = self.yaml_loader.parse_table_definition(yaml_data)
            
            if not table_def:
                self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã®è§£æã«å¤±æ•—: {table_name}")
                return []
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            sample_data = []
            for i in range(count):
                row_data = {}
                for col in table_def.business_columns:
                    # ã‚«ãƒ©ãƒ ã®å‹ã«å¿œã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                    row_data[col.name] = self._generate_column_data(col, i)
                sample_data.append(row_data)
            
            return sample_data
            
        except Exception as e:
            self.logger.error(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _generate_column_data(self, column, index: int):
        """ã‚«ãƒ©ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            column: ã‚«ãƒ©ãƒ å®šç¾©
            index (int): ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            
        Returns:
            Any: ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
        """
        # ãƒ‡ãƒ¼ã‚¿å‹ã«å¿œã˜ã¦ç”Ÿæˆ
        if column.data_type.upper().startswith('VARCHAR'):
            return self.faker_utils.generate_by_type('text')
        elif column.data_type.upper().startswith('INT'):
            return index + 1
        elif column.data_type.upper().startswith('DATE'):
            return self.faker_utils.generate_by_type('date')
        elif column.data_type.upper().startswith('TIMESTAMP'):
            return self.faker_utils.generate_by_type('datetime')
        else:
            return f"sample_{index}"
