"""
çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ - YAMLãƒ»DDLãƒ»å®šç¾©æ›¸ã®çµ±ä¸€è§£æ
å…¨ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªè§£ææ©Ÿèƒ½

è¦æ±‚ä»•æ§˜ID: PLT.1-WEB.1 (ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤è¦ä»¶)
å®Ÿè£…æ—¥: 2025-06-26
å®Ÿè£…è€…: AIé§†å‹•é–‹ç™ºãƒãƒ¼ãƒ 
"""

from typing import Optional, Dict, Any, List, Union
from pathlib import Path
import yaml
import re

from .base_parser import BaseParser
from ..core.models import TableDefinition, CheckResult, ColumnDefinition, IndexDefinition, ForeignKeyDefinition
from ..core.config import Config
from ..core.logger import get_logger
from ..core.exceptions import ParsingError, ValidationError
from ..utils.file_utils import FileUtils

logger = get_logger(__name__)


class UnifiedParser(BaseParser):
    """çµ±åˆãƒ‘ãƒ¼ã‚µãƒ¼ - YAMLãƒ»DDLãƒ»å®šç¾©æ›¸ã®çµ±ä¸€è§£æ"""
    
    def __init__(self, config: Optional[Config] = None):
        """åˆæœŸåŒ–"""
        super().__init__(config)
        self.file_utils = FileUtils(config)
        self.supported_formats = {
            '.yaml': self._parse_yaml,
            '.yml': self._parse_yaml,
            '.sql': self._parse_ddl,
            '.md': self._parse_markdown
        }
    
    def parse(self, source: Path) -> TableDefinition:
        """çµ±åˆè§£æå®Ÿè¡Œ"""
        try:
            self._validate_file_exists(source)
            self._validate_file_readable(source)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ãŸè§£æ
            extension = source.suffix.lower()
            if extension not in self.supported_formats:
                raise ParsingError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {extension}")
            
            parser_func = self.supported_formats[extension]
            table_def = parser_func(source)
            
            self.logger.info(f"è§£æå®Œäº†: {source} -> {table_def.table_name}")
            return table_def
            
        except Exception as e:
            raise self._handle_parsing_error(e, source)
    
    def validate(self, source: Path) -> List[CheckResult]:
        """çµ±åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        results = []
        
        try:
            # åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            self._validate_file_exists(source)
            self._validate_file_readable(source)
            
            # å½¢å¼åˆ¥ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            extension = source.suffix.lower()
            if extension == '.yaml' or extension == '.yml':
                results.extend(self._validate_yaml(source))
            elif extension == '.sql':
                results.extend(self._validate_ddl(source))
            elif extension == '.md':
                results.extend(self._validate_markdown(source))
            
            if not results:
                results.append(self._create_success_result(
                    f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ: {source.name}"
                ))
                
        except Exception as e:
            results.append(self._create_error_result(
                f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}",
                details=str(e)
            ))
        
        return results
    
    def get_supported_extensions(self) -> List[str]:
        """ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‚’å–å¾—"""
        return list(self.supported_formats.keys())
    
    def _parse_yaml(self, yaml_path: Path) -> TableDefinition:
        """YAMLå½¢å¼ã®è§£æ"""
        try:
            with open(yaml_path, 'r', encoding=self.config.tool.encoding) as f:
                data = yaml.safe_load(f)
            
            if not data:
                raise ParsingError("YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
            required_fields = ['table_name', 'logical_name', 'columns']
            for field in required_fields:
                if field not in data:
                    raise ValidationError(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒä¸è¶³: {field}")
            
            # TableDefinitionä½œæˆ
            table_def = TableDefinition(
                table_name=data['table_name'],
                logical_name=data['logical_name'],
                category=data.get('category', ''),
                priority=data.get('priority', 'ä¸­'),
                requirement_id=data.get('requirement_id', ''),
                comment=data.get('comment', ''),
                overview=data.get('overview', ''),
                notes=data.get('notes', []),
                rules=data.get('rules', []),
                revision_history=data.get('revision_history', [])
            )
            
            # ã‚«ãƒ©ãƒ å®šç¾©ã®è§£æ
            for col_data in data.get('columns', []):
                column = self._parse_column_from_yaml(col_data)
                table_def.columns.append(column)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©ã®è§£æ
            for idx_data in data.get('indexes', []):
                index = self._parse_index_from_yaml(idx_data)
                table_def.indexes.append(index)
            
            # å¤–éƒ¨ã‚­ãƒ¼å®šç¾©ã®è§£æ
            for fk_data in data.get('foreign_keys', []):
                foreign_key = self._parse_foreign_key_from_yaml(fk_data)
                table_def.foreign_keys.append(foreign_key)
            
            return table_def
            
        except yaml.YAMLError as e:
            raise ParsingError(f"YAMLè§£æã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            raise ParsingError(f"YAMLå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _parse_ddl(self, ddl_path: Path) -> TableDefinition:
        """DDLå½¢å¼ã®è§£æ"""
        try:
            with open(ddl_path, 'r', encoding=self.config.tool.encoding) as f:
                ddl_content = f.read()
            
            # CREATE TABLEæ–‡ã®æŠ½å‡º
            create_table_pattern = r'CREATE\s+TABLE\s+(\w+)\s*\((.*?)\);'
            match = re.search(create_table_pattern, ddl_content, re.DOTALL | re.IGNORECASE)
            
            if not match:
                raise ParsingError("CREATE TABLEæ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            table_name = match.group(1)
            columns_section = match.group(2)
            
            # TableDefinitionä½œæˆ
            table_def = TableDefinition(
                table_name=table_name,
                logical_name=table_name,  # DDLã‹ã‚‰ã¯è«–ç†åã‚’å–å¾—ã§ããªã„ãŸã‚ç‰©ç†åã‚’ä½¿ç”¨
                category='',
                priority='ä¸­',
                requirement_id='',
                comment=f'DDLã‹ã‚‰ç”Ÿæˆ: {table_name}'
            )
            
            # ã‚«ãƒ©ãƒ å®šç¾©ã®è§£æ
            columns = self._parse_columns_from_ddl(columns_section)
            table_def.columns.extend(columns)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©ã®è§£æ
            indexes = self._parse_indexes_from_ddl(ddl_content, table_name)
            table_def.indexes.extend(indexes)
            
            return table_def
            
        except Exception as e:
            raise ParsingError(f"DDLå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _parse_markdown(self, md_path: Path) -> TableDefinition:
        """Markdownå½¢å¼ã®è§£æ"""
        try:
            with open(md_path, 'r', encoding=self.config.tool.encoding) as f:
                content = f.read()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«åã®æŠ½å‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ¨æ¸¬ï¼‰
            table_name = md_path.stem.replace('ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸_', '').split('_')[0]
            
            # TableDefinitionä½œæˆï¼ˆåŸºæœ¬æƒ…å ±ã®ã¿ï¼‰
            table_def = TableDefinition(
                table_name=table_name,
                logical_name=table_name,
                category='',
                priority='ä¸­',
                requirement_id='',
                comment=f'Markdownã‹ã‚‰ç”Ÿæˆ: {table_name}'
            )
            
            # Markdownã‹ã‚‰ã®è©³ç´°è§£æã¯ä»Šå¾Œã®æ‹¡å¼µã§å®Ÿè£…
            self.logger.warning(f"Markdownè§£æã¯åŸºæœ¬æƒ…å ±ã®ã¿: {md_path}")
            
            return table_def
            
        except Exception as e:
            raise ParsingError(f"Markdownå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _parse_column_from_yaml(self, col_data: Dict[str, Any]) -> ColumnDefinition:
        """YAMLã‹ã‚‰ã‚«ãƒ©ãƒ å®šç¾©ã‚’è§£æ"""
        return ColumnDefinition(
            name=col_data['name'],
            data_type=col_data['type'],
            nullable=col_data.get('nullable', True),
            primary_key=col_data.get('primary_key', False),
            unique=col_data.get('unique', False),
            default=col_data.get('default'),
            comment=col_data.get('comment', ''),
            requirement_id=col_data.get('requirement_id', '')
        )
    
    def _parse_index_from_yaml(self, idx_data: Dict[str, Any]) -> IndexDefinition:
        """YAMLã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©ã‚’è§£æ"""
        return IndexDefinition(
            name=idx_data['name'],
            columns=idx_data['columns'],
            unique=idx_data.get('unique', False),
            comment=idx_data.get('comment', '')
        )
    
    def _parse_foreign_key_from_yaml(self, fk_data: Dict[str, Any]) -> ForeignKeyDefinition:
        """YAMLã‹ã‚‰å¤–éƒ¨ã‚­ãƒ¼å®šç¾©ã‚’è§£æ"""
        references = fk_data['references']
        return ForeignKeyDefinition(
            name=fk_data['name'],
            columns=fk_data['columns'],
            reference_table=references['table'],
            reference_columns=references['columns'],
            on_update=fk_data.get('on_update', 'RESTRICT'),
            on_delete=fk_data.get('on_delete', 'RESTRICT'),
            comment=fk_data.get('comment', '')
        )
    
    def _parse_columns_from_ddl(self, columns_section: str) -> List[ColumnDefinition]:
        """DDLã‹ã‚‰ã‚«ãƒ©ãƒ å®šç¾©ã‚’è§£æ"""
        columns = []
        
        # ã‚«ãƒ©ãƒ å®šç¾©ã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        column_pattern = r'(\w+)\s+([^,\n]+?)(?:,|\s*$)'
        matches = re.findall(column_pattern, columns_section, re.MULTILINE)
        
        for name, definition in matches:
            # åŸºæœ¬çš„ãªã‚«ãƒ©ãƒ æƒ…å ±ã‚’æŠ½å‡º
            data_type = definition.strip().split()[0]
            nullable = 'NOT NULL' not in definition.upper()
            primary_key = 'PRIMARY KEY' in definition.upper()
            unique = 'UNIQUE' in definition.upper()
            
            column = ColumnDefinition(
                name=name,
                data_type=data_type,
                nullable=nullable,
                primary_key=primary_key,
                unique=unique,
                comment=f'DDLã‹ã‚‰ç”Ÿæˆ: {name}'
            )
            columns.append(column)
        
        return columns
    
    def _parse_indexes_from_ddl(self, ddl_content: str, table_name: str) -> List[IndexDefinition]:
        """DDLã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾©ã‚’è§£æ"""
        indexes = []
        
        # CREATE INDEXæ–‡ã®æŠ½å‡º
        index_pattern = r'CREATE\s+(?:UNIQUE\s+)?INDEX\s+(\w+)\s+ON\s+' + table_name + r'\s*\((.*?)\);'
        matches = re.findall(index_pattern, ddl_content, re.IGNORECASE)
        
        for name, columns_str in matches:
            columns = [col.strip() for col in columns_str.split(',')]
            unique = 'UNIQUE' in ddl_content.upper()
            
            index = IndexDefinition(
                name=name,
                columns=columns,
                unique=unique,
                comment=f'DDLã‹ã‚‰ç”Ÿæˆ: {name}'
            )
            indexes.append(index)
        
        return indexes
    
    def _validate_yaml(self, yaml_path: Path) -> List[CheckResult]:
        """YAMLå½¢å¼ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        results = []
        
        try:
            with open(yaml_path, 'r', encoding=self.config.tool.encoding) as f:
                data = yaml.safe_load(f)
            
            # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
            required_sections = ['revision_history', 'overview', 'notes', 'rules']
            for section in required_sections:
                if section not in data:
                    results.append(self._create_error_result(
                        f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸è¶³: {section}",
                        details=f"ğŸ”´ {section} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯çµ¶å¯¾çœç•¥ç¦æ­¢ã§ã™"
                    ))
                elif section == 'overview' and len(str(data[section])) < 50:
                    results.append(self._create_error_result(
                        f"overviewæ–‡å­—æ•°ä¸è¶³: {len(str(data[section]))}æ–‡å­—",
                        details="æœ€ä½50æ–‡å­—ä»¥ä¸Šã®èª¬æ˜ãŒå¿…è¦ã§ã™"
                    ))
                elif section in ['notes', 'rules'] and len(data[section]) < 3:
                    results.append(self._create_error_result(
                        f"{section}é …ç›®æ•°ä¸è¶³: {len(data[section])}é …ç›®",
                        details="æœ€ä½3é …ç›®ä»¥ä¸ŠãŒå¿…è¦ã§ã™"
                    ))
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
            required_fields = ['table_name', 'logical_name', 'columns']
            for field in required_fields:
                if field not in data:
                    results.append(self._create_error_result(
                        f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸è¶³: {field}"
                    ))
            
        except yaml.YAMLError as e:
            results.append(self._create_error_result(
                f"YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {str(e)}"
            ))
        except Exception as e:
            results.append(self._create_error_result(
                f"YAMLãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}"
            ))
        
        return results
    
    def _validate_ddl(self, ddl_path: Path) -> List[CheckResult]:
        """DDLå½¢å¼ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        results = []
        
        try:
            with open(ddl_path, 'r', encoding=self.config.tool.encoding) as f:
                content = f.read()
            
            # CREATE TABLEæ–‡ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            if not re.search(r'CREATE\s+TABLE', content, re.IGNORECASE):
                results.append(self._create_error_result(
                    "CREATE TABLEæ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
                ))
            
        except Exception as e:
            results.append(self._create_error_result(
                f"DDLãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}"
            ))
        
        return results
    
    def _validate_markdown(self, md_path: Path) -> List[CheckResult]:
        """Markdownå½¢å¼ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        results = []
        
        try:
            with open(md_path, 'r', encoding=self.config.tool.encoding) as f:
                content = f.read()
            
            # åŸºæœ¬çš„ãªå†…å®¹ãƒã‚§ãƒƒã‚¯
            if len(content.strip()) == 0:
                results.append(self._create_error_result(
                    "Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™"
                ))
            
        except Exception as e:
            results.append(self._create_error_result(
                f"Markdownãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}"
            ))
        
        return results
