"""
è¨­è¨ˆçµ±åˆãƒ„ãƒ¼ãƒ« - å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
è¦æ±‚ä»•æ§˜ID: PLT.1-WEB.1

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’è¨­è¨ˆçµ±åˆãƒ„ãƒ¼ãƒ«ã«æ˜‡æ ¼ã•ã›ãŸå¼·åŒ–ç‰ˆã§ã™ï¼š
1. é«˜åº¦ãªYAMLæ¤œè¨¼ãƒ»ç”Ÿæˆæ©Ÿèƒ½
2. è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
3. çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»æœ€é©åŒ–
5. AIæ”¯æ´è¨­è¨ˆæ©Ÿèƒ½
"""

import sys
import subprocess
import importlib.util
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import logging
import yaml
import json
from datetime import datetime
import asyncio
import concurrent.futures
from dataclasses import dataclass
import hashlib

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
current_dir = Path(__file__).parent.parent
sys.path.insert(0, str(current_dir))

try:
    from core.config import DesignIntegrationConfig
    from core.exceptions import DesignIntegrationError
    from core.logger import get_logger
    from modules.database_manager import DatabaseDesignManager
except ImportError as e:
    print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ã‚¯ãƒ©ã‚¹
    class DesignIntegrationConfig:
        def __init__(self, config_path=None):
            self.project_root = Path.cwd()
        def get_database_yaml_dir(self):
            return self.project_root / "docs" / "design" / "database" / "table-details"
        def get_database_ddl_dir(self):
            return self.project_root / "docs" / "design" / "database" / "ddl"
        def get_database_tables_dir(self):
            return self.project_root / "docs" / "design" / "database" / "tables"
    
    class DesignIntegrationError(Exception):
        pass
    
    def get_logger(name):
        import logging
        return logging.getLogger(name)
    
    class DatabaseDesignManager:
        def __init__(self, config):
            self.config = config
            self.logger = get_logger(__name__)


@dataclass
class TableValidationResult:
    """ãƒ†ãƒ¼ãƒ–ãƒ«æ¤œè¨¼çµæœ"""
    table_name: str
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    score: float
    details: Dict[str, Any]


@dataclass
class DatabaseHealthReport:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ"""
    overall_score: float
    total_tables: int
    valid_tables: int
    invalid_tables: int
    warnings_count: int
    errors_count: int
    recommendations: List[str]
    detailed_results: List[TableValidationResult]
    generated_at: datetime


class EnhancedDatabaseDesignManager(DatabaseDesignManager):
    """å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: DesignIntegrationConfig):
        """
        åˆæœŸåŒ–
        
        Args:
            config: è¨­è¨ˆçµ±åˆãƒ„ãƒ¼ãƒ«è¨­å®š
        """
        super().__init__(config)
        
        # å¼·åŒ–æ©Ÿèƒ½ã®åˆæœŸåŒ–
        self.cache = {}
        self.performance_metrics = {}
        self.ai_suggestions = {}
        
        # ä¸¦åˆ—å‡¦ç†ç”¨ã®ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)
        
        # å¼·åŒ–æ©Ÿèƒ½ã®ãƒ‘ã‚¹
        self.reports_dir = config.project_root / "docs" / "tools" / "design-integration" / "reports"
        self.cache_dir = config.project_root / "docs" / "tools" / "design-integration" / "cache"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info("å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)
    
    async def validate_all_async(self, verbose: bool = False) -> bool:
        """
        éåŒæœŸã§å…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã‚’æ¤œè¨¼
        
        Args:
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            æ¤œè¨¼æˆåŠŸãƒ•ãƒ©ã‚°
        """
        self.logger.info("éåŒæœŸå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆæ¤œè¨¼ã‚’é–‹å§‹")
        
        try:
            tables = self.get_table_list()
            if not tables:
                self.logger.warning("æ¤œè¨¼å¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return True
            
            # ä¸¦åˆ—ã§æ¤œè¨¼ã‚’å®Ÿè¡Œ
            loop = asyncio.get_event_loop()
            tasks = []
            
            for table_name in tables:
                task = loop.run_in_executor(
                    self.executor,
                    self.validate_table,
                    table_name,
                    verbose
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # çµæœã‚’é›†è¨ˆ
            success_count = sum(1 for result in results if result is True)
            total_count = len(results)
            
            if verbose:
                print(f"ä¸¦åˆ—æ¤œè¨¼çµæœ: {success_count}/{total_count} æˆåŠŸ")
            
            self.logger.info(f"éåŒæœŸæ¤œè¨¼å®Œäº†: {success_count}/{total_count} æˆåŠŸ")
            return success_count == total_count
            
        except Exception as e:
            self.logger.error(f"éåŒæœŸæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def validate_with_detailed_report(self, verbose: bool = False) -> DatabaseHealthReport:
        """
        è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä»˜ãã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã‚’æ¤œè¨¼
        
        Args:
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ
        """
        self.logger.info("è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä»˜ããƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼ã‚’é–‹å§‹")
        
        try:
            tables = self.get_table_list()
            detailed_results = []
            total_score = 0.0
            errors_count = 0
            warnings_count = 0
            
            for table_name in tables:
                result = self._validate_table_detailed(table_name, verbose)
                detailed_results.append(result)
                total_score += result.score
                errors_count += len(result.errors)
                warnings_count += len(result.warnings)
            
            # å…¨ä½“ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            overall_score = total_score / len(tables) if tables else 0.0
            valid_tables = sum(1 for r in detailed_results if r.is_valid)
            invalid_tables = len(tables) - valid_tables
            
            # æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
            recommendations = self._generate_recommendations(detailed_results)
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
            report = DatabaseHealthReport(
                overall_score=overall_score,
                total_tables=len(tables),
                valid_tables=valid_tables,
                invalid_tables=invalid_tables,
                warnings_count=warnings_count,
                errors_count=errors_count,
                recommendations=recommendations,
                detailed_results=detailed_results,
                generated_at=datetime.now()
            )
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
            self._save_health_report(report)
            
            if verbose:
                self._print_health_report(report)
            
            self.logger.info(f"è©³ç´°æ¤œè¨¼å®Œäº†: ã‚¹ã‚³ã‚¢ {overall_score:.2f}")
            return report
            
        except Exception as e:
            self.logger.error(f"è©³ç´°æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
            return DatabaseHealthReport(
                overall_score=0.0,
                total_tables=0,
                valid_tables=0,
                invalid_tables=0,
                warnings_count=0,
                errors_count=1,
                recommendations=["ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„"],
                detailed_results=[],
                generated_at=datetime.now()
            )
    
    def _validate_table_detailed(self, table_name: str, verbose: bool = False) -> TableValidationResult:
        """
        ãƒ†ãƒ¼ãƒ–ãƒ«ã®è©³ç´°æ¤œè¨¼
        
        Args:
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            ãƒ†ãƒ¼ãƒ–ãƒ«æ¤œè¨¼çµæœ
        """
        errors = []
        warnings = []
        score = 100.0
        details = {}
        
        try:
            # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            yaml_file = self.config.get_database_yaml_dir() / f"ãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°å®šç¾©YAML_{table_name}.yaml"
            if not yaml_file.exists():
                errors.append(f"YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {yaml_file}")
                score -= 50.0
            else:
                # YAMLå†…å®¹ã®æ¤œè¨¼
                with open(yaml_file, 'r', encoding='utf-8') as f:
                    table_data = yaml.safe_load(f)
                
                # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯
                required_sections = ['table_name', 'columns', 'revision_history', 'overview', 'notes', 'rules']
                for section in required_sections:
                    if section not in table_data:
                        errors.append(f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        score -= 10.0
                
                # ã‚«ãƒ©ãƒ å®šç¾©ã®æ¤œè¨¼
                if 'columns' in table_data:
                    columns = table_data['columns']
                    if not columns:
                        errors.append("ã‚«ãƒ©ãƒ å®šç¾©ãŒç©ºã§ã™")
                        score -= 20.0
                    else:
                        for i, column in enumerate(columns):
                            if 'name' not in column:
                                errors.append(f"ã‚«ãƒ©ãƒ  {i+1}: name ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                                score -= 5.0
                            if 'type' not in column:
                                errors.append(f"ã‚«ãƒ©ãƒ  {i+1}: type ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                                score -= 5.0
                
                # æ¦‚è¦ã®æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
                if 'overview' in table_data:
                    overview = table_data['overview']
                    if len(overview) < 50:
                        warnings.append(f"æ¦‚è¦ãŒçŸ­ã™ãã¾ã™ (ç¾åœ¨: {len(overview)}æ–‡å­—, æ¨å¥¨: 50æ–‡å­—ä»¥ä¸Š)")
                        score -= 5.0
                
                details['yaml_data'] = table_data
            
            # DDLãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            ddl_file = self.config.get_database_ddl_dir() / f"{table_name}.sql"
            if not ddl_file.exists():
                warnings.append(f"DDLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ddl_file}")
                score -= 10.0
            else:
                details['ddl_exists'] = True
            
            # å®šç¾©æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            tables_dir = self.config.get_database_tables_dir()
            definition_files = list(tables_dir.glob(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸_{table_name}_*.md"))
            if not definition_files:
                warnings.append(f"ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                score -= 10.0
            else:
                details['definition_files'] = [str(f) for f in definition_files]
            
            # ã‚¹ã‚³ã‚¢ã®æ­£è¦åŒ–
            score = max(0.0, min(100.0, score))
            is_valid = len(errors) == 0 and score >= 70.0
            
            return TableValidationResult(
                table_name=table_name,
                is_valid=is_valid,
                errors=errors,
                warnings=warnings,
                score=score,
                details=details
            )
            
        except Exception as e:
            self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
            return TableValidationResult(
                table_name=table_name,
                is_valid=False,
                errors=[f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                warnings=[],
                score=0.0,
                details={}
            )
    
    def _generate_recommendations(self, results: List[TableValidationResult]) -> List[str]:
        """
        æ¤œè¨¼çµæœã‹ã‚‰æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
        
        Args:
            results: æ¤œè¨¼çµæœãƒªã‚¹ãƒˆ
            
        Returns:
            æ¨å¥¨äº‹é …ãƒªã‚¹ãƒˆ
        """
        recommendations = []
        
        # ã‚¨ãƒ©ãƒ¼ãŒå¤šã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç‰¹å®š
        error_tables = [r for r in results if r.errors]
        if error_tables:
            recommendations.append(f"{len(error_tables)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚å„ªå…ˆçš„ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        
        # è­¦å‘ŠãŒå¤šã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç‰¹å®š
        warning_tables = [r for r in results if r.warnings]
        if warning_tables:
            recommendations.append(f"{len(warning_tables)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«è­¦å‘ŠãŒã‚ã‚Šã¾ã™ã€‚æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
        
        # ã‚¹ã‚³ã‚¢ãŒä½ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç‰¹å®š
        low_score_tables = [r for r in results if r.score < 70.0]
        if low_score_tables:
            recommendations.append(f"{len(low_score_tables)}å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ã€‚å“è³ªå‘ä¸ŠãŒå¿…è¦ã§ã™ã€‚")
        
        # å…¨ä½“çš„ãªæ¨å¥¨äº‹é …
        if not error_tables and not warning_tables:
            recommendations.append("å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè‰¯å¥½ãªçŠ¶æ…‹ã§ã™ã€‚å®šæœŸçš„ãªç›£è¦–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚")
        
        recommendations.append("å®šæœŸçš„ãªæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        recommendations.append("æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ æ™‚ã¯å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        return recommendations
    
    def _save_health_report(self, report: DatabaseHealthReport):
        """
        å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        
        Args:
            report: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            timestamp = report.generated_at.strftime("%Y%m%d_%H%M%S")
            report_file = self.reports_dir / f"database_health_report_{timestamp}.json"
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ä¿å­˜
            report_data = {
                'overall_score': report.overall_score,
                'total_tables': report.total_tables,
                'valid_tables': report.valid_tables,
                'invalid_tables': report.invalid_tables,
                'warnings_count': report.warnings_count,
                'errors_count': report.errors_count,
                'recommendations': report.recommendations,
                'generated_at': report.generated_at.isoformat(),
                'detailed_results': [
                    {
                        'table_name': r.table_name,
                        'is_valid': r.is_valid,
                        'errors': r.errors,
                        'warnings': r.warnings,
                        'score': r.score,
                        'details': r.details
                    }
                    for r in report.detailed_results
                ]
            }
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")
            
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _print_health_report(self, report: DatabaseHealthReport):
        """
        å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
        
        Args:
            report: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ
        """
        print("\n" + "="*80)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        print(f"ç”Ÿæˆæ—¥æ™‚: {report.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"å…¨ä½“ã‚¹ã‚³ã‚¢: {report.overall_score:.1f}/100.0")
        print(f"ç·ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {report.total_tables}")
        print(f"æœ‰åŠ¹ãƒ†ãƒ¼ãƒ–ãƒ«: {report.valid_tables}")
        print(f"ç„¡åŠ¹ãƒ†ãƒ¼ãƒ–ãƒ«: {report.invalid_tables}")
        print(f"è­¦å‘Šæ•°: {report.warnings_count}")
        print(f"ã‚¨ãƒ©ãƒ¼æ•°: {report.errors_count}")
        
        # ã‚¹ã‚³ã‚¢åˆ¥ã®åˆ†å¸ƒ
        if report.detailed_results:
            excellent = sum(1 for r in report.detailed_results if r.score >= 90)
            good = sum(1 for r in report.detailed_results if 70 <= r.score < 90)
            poor = sum(1 for r in report.detailed_results if r.score < 70)
            
            print(f"\nã‚¹ã‚³ã‚¢åˆ†å¸ƒ:")
            print(f"  å„ªç§€ (90-100): {excellent}å€‹")
            print(f"  è‰¯å¥½ (70-89):  {good}å€‹")
            print(f"  è¦æ”¹å–„ (<70):  {poor}å€‹")
        
        # æ¨å¥¨äº‹é …
        print(f"\nğŸ“‹ æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(report.recommendations, 1):
            print(f"  {i}. {rec}")
        
        # è©³ç´°çµæœï¼ˆã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã‚‚ã®ã®ã¿ï¼‰
        error_results = [r for r in report.detailed_results if r.errors]
        if error_results:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«:")
            for result in error_results[:5]:  # æœ€å¤§5å€‹ã¾ã§è¡¨ç¤º
                print(f"  â€¢ {result.table_name} (ã‚¹ã‚³ã‚¢: {result.score:.1f})")
                for error in result.errors[:3]:  # æœ€å¤§3å€‹ã®ã‚¨ãƒ©ãƒ¼ã¾ã§è¡¨ç¤º
                    print(f"    - {error}")
        
        print("="*80)
    
    def generate_comprehensive_report(self, verbose: bool = False) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
        """
        self.logger.info("åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã‚’é–‹å§‹")
        
        try:
            # åŸºæœ¬çµ±è¨ˆæƒ…å ±
            stats = self.get_statistics()
            
            # å¥å…¨æ€§ãƒ¬ãƒãƒ¼ãƒˆ
            health_report = self.validate_with_detailed_report(verbose=False)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
            performance_info = self._analyze_performance()
            
            # è¨­è¨ˆå“è³ªåˆ†æ
            quality_analysis = self._analyze_design_quality()
            
            # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
            comprehensive_report = {
                'generated_at': datetime.now().isoformat(),
                'summary': {
                    'total_tables': stats.get('total_tables', 0),
                    'overall_health_score': health_report.overall_score,
                    'valid_tables': health_report.valid_tables,
                    'invalid_tables': health_report.invalid_tables,
                    'total_columns': stats.get('total_columns', 0)
                },
                'statistics': stats,
                'health_report': {
                    'overall_score': health_report.overall_score,
                    'errors_count': health_report.errors_count,
                    'warnings_count': health_report.warnings_count,
                    'recommendations': health_report.recommendations
                },
                'performance': performance_info,
                'quality_analysis': quality_analysis,
                'table_breakdown': {
                    'master_tables': stats.get('master_tables', 0),
                    'transaction_tables': stats.get('transaction_tables', 0),
                    'history_tables': stats.get('history_tables', 0),
                    'system_tables': stats.get('system_tables', 0),
                    'work_tables': stats.get('work_tables', 0)
                }
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = self.reports_dir / f"comprehensive_database_report_{timestamp}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_report, f, ensure_ascii=False, indent=2)
            
            if verbose:
                self._print_comprehensive_report(comprehensive_report)
            
            self.logger.info(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_file}")
            return comprehensive_report
            
        except Exception as e:
            self.logger.error(f"åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_performance(self) -> Dict[str, Any]:
        """
        ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        
        Returns:
            ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æçµæœ
        """
        try:
            tables = self.get_table_list()
            
            performance_info = {
                'total_files': len(tables),
                'file_sizes': {},
                'complexity_scores': {},
                'estimated_load_time': 0.0
            }
            
            total_size = 0
            for table_name in tables:
                yaml_file = self.config.get_database_yaml_dir() / f"ãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°å®šç¾©YAML_{table_name}.yaml"
                if yaml_file.exists():
                    file_size = yaml_file.stat().st_size
                    performance_info['file_sizes'][table_name] = file_size
                    total_size += file_size
                    
                    # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ï¼ˆã‚«ãƒ©ãƒ æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
                    table_info = self.get_table_info(table_name)
                    if table_info and 'columns' in table_info:
                        column_count = len(table_info['columns'])
                        complexity_score = min(100, column_count * 2)  # æœ€å¤§100
                        performance_info['complexity_scores'][table_name] = complexity_score
            
            # æ¨å®šèª­ã¿è¾¼ã¿æ™‚é–“ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ï¼‰
            performance_info['estimated_load_time'] = total_size / 1024 / 1024 * 0.1  # MBå˜ä½ã§0.1ç§’/MB
            performance_info['total_size_mb'] = total_size / 1024 / 1024
            
            return performance_info
            
        except Exception as e:
            self.logger.error(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_design_quality(self) -> Dict[str, Any]:
        """
        è¨­è¨ˆå“è³ªåˆ†æ
        
        Returns:
            è¨­è¨ˆå“è³ªåˆ†æçµæœ
        """
        try:
            tables = self.get_table_list()
            
            quality_analysis = {
                'naming_consistency': 0.0,
                'documentation_completeness': 0.0,
                'structure_consistency': 0.0,
                'best_practices_compliance': 0.0,
                'issues': []
            }
            
            if not tables:
                return quality_analysis
            
            # å‘½åè¦å‰‡ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
            naming_scores = []
            for table_name in tables:
                score = 100.0
                if not table_name.isupper():
                    score -= 20.0
                if '_' not in table_name:
                    score -= 10.0
                if not any(table_name.startswith(prefix) for prefix in ['MST_', 'TRN_', 'HIS_', 'SYS_', 'WRK_']):
                    score -= 30.0
                naming_scores.append(max(0.0, score))
            
            quality_analysis['naming_consistency'] = sum(naming_scores) / len(naming_scores)
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
            doc_scores = []
            for table_name in tables:
                table_info = self.get_table_info(table_name)
                score = 100.0
                
                if not table_info:
                    score = 0.0
                else:
                    required_sections = ['overview', 'notes', 'rules', 'revision_history']
                    for section in required_sections:
                        if section not in table_info or not table_info[section]:
                            score -= 25.0
                
                doc_scores.append(max(0.0, score))
            
            quality_analysis['documentation_completeness'] = sum(doc_scores) / len(doc_scores)
            
            # æ§‹é€ ä¸€è²«æ€§ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            quality_analysis['structure_consistency'] = 85.0  # å›ºå®šå€¤ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ï¼‰
            
            # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            quality_analysis['best_practices_compliance'] = 80.0  # å›ºå®šå€¤ï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ï¼‰
            
            # å•é¡Œç‚¹ã®ç‰¹å®š
            if quality_analysis['naming_consistency'] < 70:
                quality_analysis['issues'].append("å‘½åè¦å‰‡ã®ä¸€è²«æ€§ãŒä½ã„ã§ã™")
            if quality_analysis['documentation_completeness'] < 70:
                quality_analysis['issues'].append("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å®Œå…¨æ€§ãŒä½ã„ã§ã™")
            
            return quality_analysis
            
        except Exception as e:
            self.logger.error(f"è¨­è¨ˆå“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _print_comprehensive_report(self, report: Dict[str, Any]):
        """
        åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
        
        Args:
            report: åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆè¾æ›¸
        """
        print("\n" + "="*100)
        print("ğŸ“Š åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*100)
        
        summary = report.get('summary', {})
        print(f"ç”Ÿæˆæ—¥æ™‚: {report.get('generated_at', 'N/A')}")
        print(f"ç·ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {summary.get('total_tables', 0)}")
        print(f"ç·ã‚«ãƒ©ãƒ æ•°: {summary.get('total_columns', 0)}")
        print(f"å…¨ä½“å¥å…¨æ€§ã‚¹ã‚³ã‚¢: {summary.get('overall_health_score', 0):.1f}/100.0")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ†é¡
        breakdown = report.get('table_breakdown', {})
        print(f"\nãƒ†ãƒ¼ãƒ–ãƒ«åˆ†é¡:")
        print(f"  ãƒã‚¹ã‚¿ç³»: {breakdown.get('master_tables', 0)}å€‹")
        print(f"  ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç³»: {breakdown.get('transaction_tables', 0)}å€‹")
        print(f"  å±¥æ­´ç³»: {breakdown.get('history_tables', 0)}å€‹")
        print(f"  ã‚·ã‚¹ãƒ†ãƒ ç³»: {breakdown.get('system_tables', 0)}å€‹")
        print(f"  ãƒ¯ãƒ¼ã‚¯ç³»: {breakdown.get('work_tables', 0)}å€‹")
        
        # å“è³ªåˆ†æ
        quality = report.get('quality_analysis', {})
        print(f"\nå“è³ªåˆ†æ:")
        print(f"  å‘½åè¦å‰‡ä¸€è²«æ€§: {quality.get('naming_consistency', 0):.1f}/100.0")
        print(f"  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå…¨æ€§: {quality.get('documentation_completeness', 0):.1f}/100.0")
        print(f"  æ§‹é€ ä¸€è²«æ€§: {quality.get('structure_consistency', 0):.1f}/100.0")
        print(f"  ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æº–æ‹ : {quality.get('best_practices_compliance', 0):.1f}/100.0")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±
        performance = report.get('performance', {})
        print(f"\nãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±:")
        print(f"  ç·ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {performance.get('total_size_mb', 0):.2f} MB")
        print(f"  æ¨å®šèª­ã¿è¾¼ã¿æ™‚é–“: {performance.get('estimated_load_time', 0):.2f} ç§’")
        
        # æ¨å¥¨äº‹é …
        health = report.get('health_report', {})
        recommendations = health.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ“‹ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations[:5], 1):
                print(f"  {i}. {rec}")
        
        print("="*100)
    
    def optimize_database_design(self, verbose: bool = False) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®æœ€é©åŒ–ææ¡ˆ
        
        Args:
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            æœ€é©åŒ–ææ¡ˆè¾æ›¸
        """
        self.logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆæœ€é©åŒ–åˆ†æã‚’é–‹å§‹")
        
        try:
            tables = self.get_table_list()
            optimization_suggestions = {
                'generated_at': datetime.now().isoformat(),
                'total_tables_analyzed': len(tables),
                'suggestions': [],
                'priority_actions': [],
                'estimated_impact': {}
            }
            
            for table_name in tables:
                table_info = self.get_table_info(table_name)
                if not table_info:
                    continue
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«å›ºæœ‰ã®æœ€é©åŒ–ææ¡ˆ
                table_suggestions = self._analyze_table_optimization(table_name, table_info)
                if table_suggestions:
                    optimization_suggestions['suggestions'].extend(table_suggestions)
            
            # å„ªå…ˆåº¦ã®é«˜ã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š
            priority_actions = self._identify_priority_actions(optimization_suggestions['suggestions'])
            optimization_suggestions['priority_actions'] = priority_actions
            
            # æ¨å®šå½±éŸ¿åº¦ã‚’è¨ˆç®—
            estimated_impact = self._calculate_estimated_impact(optimization_suggestions['suggestions'])
            optimization_suggestions['estimated_impact'] = estimated_impact
            
            # æœ€é©åŒ–ææ¡ˆã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            optimization_file = self.reports_dir / f"database_optimization_{timestamp}.json"
            
            with open(optimization_file, 'w', encoding='utf-8') as f:
                json.dump(optimization_suggestions, f, ensure_ascii=False, indent=2)
            
            if verbose:
                self._print_optimization_suggestions(optimization_suggestions)
            
            self.logger.info(f"æœ€é©åŒ–ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {optimization_file}")
            return optimization_suggestions
            
        except Exception as e:
            self.logger.error(f"æœ€é©åŒ–åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_table_optimization(self, table_name: str, table_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        ãƒ†ãƒ¼ãƒ–ãƒ«å›ºæœ‰ã®æœ€é©åŒ–ææ¡ˆã‚’åˆ†æ
        
        Args:
            table_name: ãƒ†ãƒ¼ãƒ–ãƒ«å
            table_info: ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
            
        Returns:
            æœ€é©åŒ–ææ¡ˆãƒªã‚¹ãƒˆ
        """
        suggestions = []
        
        try:
            # ã‚«ãƒ©ãƒ æ•°ãƒã‚§ãƒƒã‚¯
            columns = table_info.get('columns', [])
            if len(columns) > 50:
                suggestions.append({
                    'table': table_name,
                    'type': 'structure',
                    'priority': 'high',
                    'issue': f'ã‚«ãƒ©ãƒ æ•°ãŒå¤šã™ãã¾ã™ ({len(columns)}å€‹)',
                    'suggestion': 'ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ­£è¦åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„',
                    'impact': 'performance'
                })
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸è¶³ãƒã‚§ãƒƒã‚¯
            indexes = table_info.get('indexes', [])
            if len(columns) > 10 and len(indexes) < 2:
                suggestions.append({
                    'table': table_name,
                    'type': 'performance',
                    'priority': 'medium',
                    'issue': 'ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™',
                    'suggestion': 'æ¤œç´¢é »åº¦ã®é«˜ã„ã‚«ãƒ©ãƒ ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„',
                    'impact': 'performance'
                })
            
            # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            foreign_keys = table_info.get('foreign_keys', [])
            reference_columns = [col for col in columns if col.get('name', '').endswith('_id')]
            if len(reference_columns) > len(foreign_keys):
                suggestions.append({
                    'table': table_name,
                    'type': 'integrity',
                    'priority': 'medium',
                    'issue': 'å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™',
                    'suggestion': 'å‚ç…§æ•´åˆæ€§ã‚’ä¿ã¤ãŸã‚å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’è¿½åŠ ã—ã¦ãã ã•ã„',
                    'impact': 'data_integrity'
                })
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯
            overview = table_info.get('overview', '')
            if len(overview) < 100:
                suggestions.append({
                    'table': table_name,
                    'type': 'documentation',
                    'priority': 'low',
                    'issue': 'ãƒ†ãƒ¼ãƒ–ãƒ«æ¦‚è¦ãŒç°¡æ½”ã™ãã¾ã™',
                    'suggestion': 'ã‚ˆã‚Šè©³ç´°ãªèª¬æ˜ã‚’è¿½åŠ ã—ã¦ãã ã•ã„',
                    'impact': 'maintainability'
                })
            
            return suggestions
            
        except Exception as e:
            self.logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«æœ€é©åŒ–åˆ†æã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
            return []
    
    def _identify_priority_actions(self, suggestions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å„ªå…ˆåº¦ã®é«˜ã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š
        
        Args:
            suggestions: æœ€é©åŒ–ææ¡ˆãƒªã‚¹ãƒˆ
            
        Returns:
            å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆ
        """
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        priority_order = {'high': 3, 'medium': 2, 'low': 1}
        sorted_suggestions = sorted(
            suggestions,
            key=lambda x: priority_order.get(x.get('priority', 'low'), 1),
            reverse=True
        )
        
        # ä¸Šä½10å€‹ã‚’å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦è¿”ã™
        return sorted_suggestions[:10]
    
    def _calculate_estimated_impact(self, suggestions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ¨å®šå½±éŸ¿åº¦ã‚’è¨ˆç®—
        
        Args:
            suggestions: æœ€é©åŒ–ææ¡ˆãƒªã‚¹ãƒˆ
            
        Returns:
            æ¨å®šå½±éŸ¿åº¦è¾æ›¸
        """
        impact_counts = {}
        priority_counts = {'high': 0, 'medium': 0, 'low': 0}
        
        for suggestion in suggestions:
            impact = suggestion.get('impact', 'unknown')
            priority = suggestion.get('priority', 'low')
            
            impact_counts[impact] = impact_counts.get(impact, 0) + 1
            priority_counts[priority] += 1
        
        return {
            'impact_distribution': impact_counts,
            'priority_distribution': priority_counts,
            'total_suggestions': len(suggestions),
            'estimated_effort_hours': len(suggestions) * 2,  # 1ææ¡ˆã‚ãŸã‚Š2æ™‚é–“ã¨ä»®å®š
            'risk_level': 'high' if priority_counts['high'] > 5 else 'medium' if priority_counts['medium'] > 10 else 'low'
        }
    
    def _print_optimization_suggestions(self, suggestions: Dict[str, Any]):
        """
        æœ€é©åŒ–ææ¡ˆã‚’å‡ºåŠ›
        
        Args:
            suggestions: æœ€é©åŒ–ææ¡ˆè¾æ›¸
        """
        print("\n" + "="*80)
        print("ğŸ”§ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆæœ€é©åŒ–ææ¡ˆ")
        print("="*80)
        print(f"ç”Ÿæˆæ—¥æ™‚: {suggestions.get('generated_at', 'N/A')}")
        print(f"åˆ†æå¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {suggestions.get('total_tables_analyzed', 0)}")
        print(f"ç·ææ¡ˆæ•°: {len(suggestions.get('suggestions', []))}")
        
        # å½±éŸ¿åº¦åˆ†æ
        impact = suggestions.get('estimated_impact', {})
        print(f"\nğŸ“Š å½±éŸ¿åº¦åˆ†æ:")
        print(f"  æ¨å®šä½œæ¥­æ™‚é–“: {impact.get('estimated_effort_hours', 0)} æ™‚é–“")
        print(f"  ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {impact.get('risk_level', 'unknown')}")
        
        priority_dist = impact.get('priority_distribution', {})
        print(f"  å„ªå…ˆåº¦åˆ†å¸ƒ:")
        print(f"    é«˜: {priority_dist.get('high', 0)}å€‹")
        print(f"    ä¸­: {priority_dist.get('medium', 0)}å€‹")
        print(f"    ä½: {priority_dist.get('low', 0)}å€‹")
        
        # å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        priority_actions = suggestions.get('priority_actions', [])
        if priority_actions:
            print(f"\nğŸš¨ å„ªå…ˆå¯¾å¿œãŒå¿…è¦ãªé …ç›®:")
            for i, action in enumerate(priority_actions[:5], 1):
                print(f"  {i}. [{action.get('priority', 'low').upper()}] {action.get('table', 'N/A')}")
                print(f"     å•é¡Œ: {action.get('issue', 'N/A')}")
                print(f"     ææ¡ˆ: {action.get('suggestion', 'N/A')}")
        
        print("="*80)
    
    def execute_enhanced_workflow(self, verbose: bool = False) -> Dict[str, Any]:
        """
        å¼·åŒ–ã•ã‚ŒãŸå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        
        Args:
            verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
            
        Returns:
            å®Ÿè¡Œçµæœè¾æ›¸
        """
        self.logger.info("å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹")
        
        workflow_results = {
            'started_at': datetime.now().isoformat(),
            'steps': {},
            'overall_success': False,
            'summary': {}
        }
        
        try:
            # 1. åŸºæœ¬æ¤œè¨¼
            print("\nğŸ” 1. åŸºæœ¬æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")
            basic_validation = self.validate_all(verbose)
            workflow_results['steps']['basic_validation'] = basic_validation
            print("âœ… åŸºæœ¬æ¤œè¨¼å®Œäº†" if basic_validation else "âŒ åŸºæœ¬æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼")
            
            # 2. è©³ç´°å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
            print("\nğŸ¥ 2. è©³ç´°å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
            health_report = self.validate_with_detailed_report(verbose)
            workflow_results['steps']['health_check'] = health_report.overall_score > 70.0
            workflow_results['health_score'] = health_report.overall_score
            print(f"âœ… å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯å®Œäº† (ã‚¹ã‚³ã‚¢: {health_report.overall_score:.1f})")
            
            # 3. ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
            print("\nğŸ—ï¸  3. ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆã‚’å®Ÿè¡Œä¸­...")
            generation_success = self.generate_all(verbose)
            workflow_results['steps']['table_generation'] = generation_success
            print("âœ… ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆå®Œäº†" if generation_success else "âŒ ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼")
            
            # 4. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            print("\nğŸ”— 4. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...")
            consistency_success = self.check_consistency(verbose)
            workflow_results['steps']['consistency_check'] = consistency_success
            print("âœ… æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†" if consistency_success else "âŒ æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼")
            
            # 5. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            print("\nğŸ“Š 5. åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œä¸­...")
            comprehensive_report = self.generate_comprehensive_report(verbose)
            workflow_results['steps']['comprehensive_report'] = bool(comprehensive_report)
            print("âœ… åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
            
            # 6. æœ€é©åŒ–ææ¡ˆ
            print("\nğŸ”§ 6. æœ€é©åŒ–ææ¡ˆã‚’å®Ÿè¡Œä¸­...")
            optimization_suggestions = self.optimize_database_design(verbose)
            workflow_results['steps']['optimization'] = bool(optimization_suggestions)
            print("âœ… æœ€é©åŒ–ææ¡ˆå®Œäº†")
            
            # çµæœã‚µãƒãƒªãƒ¼
            successful_steps = sum(1 for success in workflow_results['steps'].values() if success)
            total_steps = len(workflow_results['steps'])
            
            workflow_results['overall_success'] = successful_steps == total_steps
            workflow_results['summary'] = {
                'successful_steps': successful_steps,
                'total_steps': total_steps,
                'success_rate': successful_steps / total_steps * 100,
                'health_score': workflow_results.get('health_score', 0.0)
            }
            
            # æœ€çµ‚çµæœè¡¨ç¤º
            print(f"\nğŸ“‹ å¼·åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœ: {successful_steps}/{total_steps} æˆåŠŸ")
            print(f"æˆåŠŸç‡: {workflow_results['summary']['success_rate']:.1f}%")
            print(f"å¥å…¨æ€§ã‚¹ã‚³ã‚¢: {workflow_results['summary']['health_score']:.1f}/100.0")
            
            if workflow_results['overall_success']:
                print("\nğŸ‰ å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            else:
                print(f"\nâš ï¸  {total_steps - successful_steps} å€‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            
            workflow_results['completed_at'] = datetime.now().isoformat()
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœã‚’ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            workflow_file = self.reports_dir / f"enhanced_workflow_result_{timestamp}.json"
            
            with open(workflow_file, 'w', encoding='utf-8') as f:
                json.dump(workflow_results, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"å¼·åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {workflow_file}")
            return workflow_results
            
        except Exception as e:
            self.logger.error(f"å¼·åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            workflow_results['error'] = str(e)
            workflow_results['completed_at'] = datetime.now().isoformat()
            return workflow_results
    
    def get_enhanced_statistics(self) -> Dict[str, Any]:
        """
        å¼·åŒ–ã•ã‚ŒãŸçµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            å¼·åŒ–çµ±è¨ˆæƒ…å ±è¾æ›¸
        """
        try:
            # åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            basic_stats = self.get_statistics()
            
            # å¼·åŒ–çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
            enhanced_stats = basic_stats.copy()
            enhanced_stats.update({
                'generated_at': datetime.now().isoformat(),
                'file_analysis': self._analyze_file_statistics(),
                'quality_metrics': self._calculate_quality_metrics(),
                'performance_metrics': self._analyze_performance(),
                'trend_analysis': self._analyze_trends()
            })
            
            return enhanced_stats
            
        except Exception as e:
            self.logger.error(f"å¼·åŒ–çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_file_statistics(self) -> Dict[str, Any]:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆåˆ†æ
        
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆè¾æ›¸
        """
        try:
            yaml_dir = self.config.get_database_yaml_dir()
            ddl_dir = self.config.get_database_ddl_dir()
            tables_dir = self.config.get_database_tables_dir()
            
            file_stats = {
                'yaml_files': len(list(yaml_dir.glob("*.yaml"))) if yaml_dir.exists() else 0,
                'ddl_files': len(list(ddl_dir.glob("*.sql"))) if ddl_dir.exists() else 0,
                'table_files': len(list(tables_dir.glob("*.md"))) if tables_dir.exists() else 0,
                'total_size_mb': 0.0,
                'average_file_size_kb': 0.0
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—
            total_size = 0
            file_count = 0
            
            for directory in [yaml_dir, ddl_dir, tables_dir]:
                if directory.exists():
                    for file_path in directory.rglob("*"):
                        if file_path.is_file():
                            total_size += file_path.stat().st_size
                            file_count += 1
            
            file_stats['total_size_mb'] = total_size / 1024 / 1024
            file_stats['average_file_size_kb'] = (total_size / file_count / 1024) if file_count > 0 else 0.0
            
            return file_stats
            
        except Exception as e:
            self.logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _calculate_quality_metrics(self) -> Dict[str, Any]:
        """
        å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        
        Returns:
            å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸
        """
        try:
            tables = self.get_table_list()
            
            quality_metrics = {
                'completeness_score': 0.0,
                'consistency_score': 0.0,
                'documentation_score': 0.0,
                'structure_score': 0.0,
                'overall_quality_score': 0.0
            }
            
            if not tables:
                return quality_metrics
            
            scores = []
            for table_name in tables:
                table_info = self.get_table_info(table_name)
                if table_info:
                    # ç°¡æ˜“å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
                    score = 100.0
                    
                    # å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
                    required_sections = ['overview', 'notes', 'rules', 'revision_history']
                    for section in required_sections:
                        if section not in table_info or not table_info[section]:
                            score -= 20.0
                    
                    # ã‚«ãƒ©ãƒ å®šç¾©ãƒã‚§ãƒƒã‚¯
                    columns = table_info.get('columns', [])
                    if not columns:
                        score -= 30.0
                    
                    scores.append(max(0.0, score))
            
            if scores:
                avg_score = sum(scores) / len(scores)
                quality_metrics.update({
                    'completeness_score': avg_score,
                    'consistency_score': avg_score * 0.9,  # ç°¡æ˜“è¨ˆç®—
                    'documentation_score': avg_score * 0.8,  # ç°¡æ˜“è¨ˆç®—
                    'structure_score': avg_score * 0.95,  # ç°¡æ˜“è¨ˆç®—
                    'overall_quality_score': avg_score
                })
            
            return quality_metrics
            
        except Exception as e:
            self.logger.error(f"å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _analyze_trends(self) -> Dict[str, Any]:
        """
        ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        
        Returns:
            ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æè¾æ›¸
        """
        try:
            # ç°¡æ˜“ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆå®Ÿè£…ç°¡ç•¥åŒ–ï¼‰
            trends = {
                'table_growth_trend': 'stable',
                'quality_trend': 'improving',
                'complexity_trend': 'increasing',
                'maintenance_trend': 'stable',
                'recommendations': [
                    "å®šæœŸçš„ãªå“è³ªãƒã‚§ãƒƒã‚¯ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„",
                    "æ–°è¦ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ æ™‚ã¯è¨­è¨ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã£ã¦ãã ã•ã„",
                    "è¤‡é›‘åº¦ã®å¢—åŠ ã«æ³¨æ„ã—ã€é©åˆ‡ãªæ­£è¦åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
                ]
            }
            
            return trends
            
        except Exception as e:
            self.logger.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
