#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SQL ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ Prisma seed.ts ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¦æ±‚ä»•æ§˜ID: PLT.1-DB.1 - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥è‡ªå‹•åŒ–
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

class SQLToSeedConverter:
    def __init__(self, sql_data_dir: str, output_file: str):
        self.sql_data_dir = Path(sql_data_dir)
        self.output_file = Path(output_file)
        self.table_data = {}
        self.table_order = []
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆSQLå -> Prismaåï¼‰
        self.table_mapping = {
            'MST_Tenant': 'tenant',
            'MST_Department': 'department', 
            'MST_Position': 'position',
            'MST_JobType': 'jobType',
            'MST_Role': 'role',
            'MST_Permission': 'permission',
            'MST_SkillCategory': 'skillCategory',
            'MST_SkillItem': 'skillItem',
            'MST_Employee': 'employee',
            'MST_UserAuth': 'userAuth',
            'MST_UserRole': 'userRole',
            'TRN_SkillRecord': 'skillRecord',
            'MST_SkillGrade': 'skillGrade',
            'MST_SkillHierarchy': 'skillHierarchy',
            'MST_Certification': 'certification',
            'MST_CertificationRequirement': 'certificationRequirement',
            'MST_CareerPlan': 'careerPlan',
            'MST_TrainingProgram': 'trainingProgram',
            'MST_SystemConfig': 'systemConfig',
            'MST_TenantSettings': 'tenantSettings',
            'MST_NotificationSettings': 'notificationSettings',
            'MST_NotificationTemplate': 'notificationTemplate',
            'MST_ReportTemplate': 'reportTemplate',
            'TRN_EmployeeSkillGrade': 'employeeSkillGrade',
            'TRN_GoalProgress': 'goalProgress',
            'TRN_Notification': 'notification',
            'TRN_PDU': 'pdu',
            'TRN_ProjectRecord': 'projectRecord',
            'TRN_SkillEvidence': 'skillEvidence',
            'TRN_TrainingHistory': 'trainingHistory',
            'HIS_AuditLog': 'auditLog',
            'HIS_NotificationLog': 'notificationLog',
            'HIS_TenantBilling': 'tenantBilling',
            'SYS_BackupHistory': 'backupHistory',
            'SYS_IntegrationConfig': 'integrationConfig',
            'SYS_MasterData': 'masterData',
            'SYS_SkillIndex': 'skillIndex',
            'SYS_SkillMatrix': 'skillMatrix',
            'SYS_SystemLog': 'systemLog',
            'SYS_TenantUsage': 'tenantUsage',
            'SYS_TokenStore': 'tokenStore',
            'WRK_BatchJobLog': 'batchJobLog',
        }
        
        # ä¾å­˜é–¢ä¿‚ã®å®šç¾©ï¼ˆå‚ç…§ã•ã‚Œã‚‹å´ -> å‚ç…§ã™ã‚‹å´ã®é †åºï¼‰
        self.dependency_order = [
            'MST_Tenant',
            'MST_Department', 
            'MST_Position',
            'MST_JobType',
            'MST_Role',
            'MST_Permission',
            'MST_SkillCategory',
            'MST_SkillItem',
            'MST_SkillGrade',
            'MST_SkillHierarchy',
            'MST_Certification',
            'MST_Employee',
            'MST_UserAuth',
            'MST_UserRole',
            'MST_CertificationRequirement',
            'MST_CareerPlan',
            'MST_TrainingProgram',
            'MST_SystemConfig',
            'MST_TenantSettings',
            'MST_NotificationSettings',
            'MST_NotificationTemplate',
            'MST_ReportTemplate',
            'TRN_SkillRecord',
            'TRN_EmployeeSkillGrade',
            'TRN_GoalProgress',
            'TRN_Notification',
            'TRN_PDU',
            'TRN_ProjectRecord',
            'TRN_SkillEvidence',
            'TRN_TrainingHistory',
            'HIS_AuditLog',
            'HIS_NotificationLog',
            'HIS_TenantBilling',
            'SYS_BackupHistory',
            'SYS_IntegrationConfig',
            'SYS_MasterData',
            'SYS_SkillIndex',
            'SYS_SkillMatrix',
            'SYS_SystemLog',
            'SYS_TenantUsage',
            'SYS_TokenStore',
            'WRK_BatchJobLog',
        ]

    def parse_sql_file(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’æŠ½å‡º
            table_match = re.search(r'INSERT INTO (\w+)', content, re.IGNORECASE)
            if not table_match:
                return None
                
            table_name = table_match.group(1)
            
            # ã‚«ãƒ©ãƒ åã‚’æŠ½å‡º
            columns_match = re.search(r'INSERT INTO \w+\s*\(\s*([^)]+)\s*\)', content, re.IGNORECASE | re.DOTALL)
            if not columns_match:
                return None
                
            columns_text = columns_match.group(1)
            columns = [col.strip().strip(',') for col in columns_text.split('\n') if col.strip()]
            columns = [col for col in columns if col and not col.startswith('--')]
            
            # VALUESå¥ã‚’æŠ½å‡º
            values_match = re.search(r'VALUES\s*(.+?)(?:;|\n--)', content, re.IGNORECASE | re.DOTALL)
            if not values_match:
                return None
                
            values_text = values_match.group(1)
            
            # å„è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            rows = []
            # VALUESå†…ã®å„è¡Œã‚’è§£æï¼ˆæ‹¬å¼§ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†ï¼‰
            row_pattern = r'\(\s*([^)]+)\s*\)'
            row_matches = re.findall(row_pattern, values_text, re.DOTALL)
            
            for row_match in row_matches:
                row_values = self.parse_row_values(row_match)
                if len(row_values) == len(columns):
                    row_data = dict(zip(columns, row_values))
                    rows.append(row_data)
            
            return {
                'table_name': table_name,
                'columns': columns,
                'rows': rows
            }
            
        except Exception as e:
            print(f"Error parsing {file_path}: {e}")
            return None

    def parse_row_values(self, row_text: str) -> List[str]:
        """è¡Œã®å€¤ã‚’è§£æ"""
        values = []
        current_value = ""
        in_quotes = False
        quote_char = None
        paren_depth = 0
        
        i = 0
        while i < len(row_text):
            char = row_text[i]
            
            if not in_quotes:
                if char in ["'", '"']:
                    in_quotes = True
                    quote_char = char
                    current_value += char
                elif char == '(':
                    paren_depth += 1
                    current_value += char
                elif char == ')':
                    paren_depth -= 1
                    current_value += char
                elif char == ',' and paren_depth == 0:
                    values.append(current_value.strip())
                    current_value = ""
                else:
                    current_value += char
            else:
                current_value += char
                if char == quote_char:
                    # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã¦ã„ãªã„å¼•ç”¨ç¬¦ã®çµ‚äº†ã‚’ãƒã‚§ãƒƒã‚¯
                    if i == 0 or row_text[i-1] != '\\':
                        in_quotes = False
                        quote_char = None
            
            i += 1
        
        if current_value.strip():
            values.append(current_value.strip())
        
        return values

    def convert_value(self, value: str, column_name: str) -> str:
        """SQLã®å€¤ã‚’TypeScript/Prismaã®å€¤ã«å¤‰æ›"""
        value = value.strip()
        
        # NULLå€¤
        if value.upper() == 'NULL':
            return 'null'
        
        # æ–‡å­—åˆ—å€¤ï¼ˆå¼•ç”¨ç¬¦ã§å›²ã¾ã‚Œã¦ã„ã‚‹ï¼‰
        if (value.startswith("'") and value.endswith("'")) or (value.startswith('"') and value.endswith('"')):
            # å¼•ç”¨ç¬¦ã‚’é™¤å»ã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            inner_value = value[1:-1]
            # JavaScriptã®æ–‡å­—åˆ—ã¨ã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
            inner_value = inner_value.replace('\\', '\\\\').replace("'", "\\'").replace('"', '\\"')
            return f"'{inner_value}'"
        
        # æ•°å€¤ï¼ˆæ•´æ•°ãƒ»å°æ•°ï¼‰
        if re.match(r'^-?\d+(\.\d+)?$', value):
            return value
        
        # ãƒ–ãƒ¼ãƒ«å€¤
        if value.upper() in ['TRUE', 'FALSE']:
            return value.lower()
        
        # æ—¥ä»˜ãƒ»æ™‚åˆ»ï¼ˆISOå½¢å¼ã«å¤‰æ›ï¼‰
        date_patterns = [
            r"'\d{4}-\d{2}-\d{2}'",
            r"'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}'",
            r"'\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}'"
        ]
        
        for pattern in date_patterns:
            if re.match(pattern, value):
                date_str = value[1:-1]  # å¼•ç”¨ç¬¦ã‚’é™¤å»
                return f"new Date('{date_str}')"
        
        # JSONæ–‡å­—åˆ—
        if value.startswith("'{") and value.endswith("}'"):
            try:
                json_str = value[1:-1]  # å¤–å´ã®å¼•ç”¨ç¬¦ã‚’é™¤å»
                # JSONã¨ã—ã¦è§£æã—ã¦ã¿ã‚‹
                json.loads(json_str)
                return json_str
            except:
                pass
        
        # ãã®ä»–ã¯æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†
        if not value.startswith("'"):
            value = f"'{value}'"
        
        return value

    def generate_upsert_code(self, table_name: str, data: Dict[str, Any]) -> str:
        """ãƒ†ãƒ¼ãƒ–ãƒ«ã®upsertã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        prisma_table = self.table_mapping.get(table_name, table_name.lower())
        rows = data['rows']
        
        if not rows:
            return ""
        
        # ä¸»ã‚­ãƒ¼ã‚’æ¨å®šï¼ˆé€šå¸¸ã¯æœ€åˆã®ã‚«ãƒ©ãƒ ã¾ãŸã¯_idã§çµ‚ã‚ã‚‹ã‚«ãƒ©ãƒ ï¼‰
        columns = data['columns']
        primary_key = None
        
        # ä¸€èˆ¬çš„ãªä¸»ã‚­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        for col in columns:
            if col.lower() in ['id', 'code', f'{table_name.lower()}_id', f'{table_name.lower()}_code']:
                primary_key = col
                break
        
        if not primary_key and columns:
            primary_key = columns[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ã‚«ãƒ©ãƒ 
        
        code_lines = []
        code_lines.append(f"    // {table_name} ({data.get('description', 'ãƒ‡ãƒ¼ã‚¿')})")
        code_lines.append(f"    console.log('ğŸ“Š {table_name}ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥ä¸­...')")
        code_lines.append(f"    const {prisma_table}Data = await Promise.all([")
        
        for i, row in enumerate(rows):
            # whereã‚¯ã‚¨ãƒªç”¨ã®æ¡ä»¶
            where_value = self.convert_value(row.get(primary_key, ''), primary_key)
            
            code_lines.append(f"      prisma.{prisma_table}.upsert({{")
            code_lines.append(f"        where: {{ {primary_key}: {where_value} }},")
            code_lines.append(f"        update: {{}},")
            code_lines.append(f"        create: {{")
            
            # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
            for col, val in row.items():
                if val and val.upper() != 'NULL':
                    converted_val = self.convert_value(val, col)
                    code_lines.append(f"          {col}: {converted_val},")
            
            code_lines.append(f"        }},")
            code_lines.append(f"      }}),")
        
        code_lines.append(f"    ])")
        code_lines.append("")
        
        return "\n".join(code_lines)

    def generate_seed_file(self):
        """seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        # SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        for sql_file in self.sql_data_dir.glob("*.sql"):
            if sql_file.name.endswith('_sample_data.sql'):
                data = self.parse_sql_file(sql_file)
                if data:
                    table_name = data['table_name']
                    self.table_data[table_name] = data
                    print(f"Parsed: {table_name} ({len(data['rows'])} rows)")

        # seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(self.generate_header())
            
            # ä¾å­˜é–¢ä¿‚é †ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‡¦ç†
            for table_name in self.dependency_order:
                if table_name in self.table_data:
                    upsert_code = self.generate_upsert_code(table_name, self.table_data[table_name])
                    if upsert_code:
                        f.write(upsert_code)
                        f.write("\n")
            
            f.write(self.generate_footer())
        
        print(f"Generated seed file: {self.output_file}")

    def generate_header(self) -> str:
        """seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ç”Ÿæˆ"""
        return '''// è¦æ±‚ä»•æ§˜ID: PLT.1-DB.1 - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
// è¨­è¨ˆæ›¸: docs/design/database/data/ é…ä¸‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿SQLãƒ•ã‚¡ã‚¤ãƒ«ç¾¤
// è‡ªå‹•ç”Ÿæˆæ—¥æ™‚: ''' + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '''
import { PrismaClient } from '@prisma/client'

const prisma = new PrismaClient()

async function main() {
  console.log('ğŸŒ± ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚’é–‹å§‹ã—ã¾ã™...')

  try {
'''

    def generate_footer(self) -> str:
        """seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒƒã‚¿ãƒ¼ã‚’ç”Ÿæˆ"""
        return '''
    console.log('âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥ãŒå®Œäº†ã—ã¾ã—ãŸï¼')
    console.log('ğŸ“‹ æŠ•å…¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã¯ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„')
    console.log('')
    console.log('ğŸ” ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±:')
    console.log('   ç®¡ç†è€…:')
    console.log('     ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: admin@skill-report.local')
    console.log('     ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: password')
    console.log('   ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼1:')
    console.log('     ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: yamada.taro@company.com')
    console.log('     ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: password')
    console.log('   ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼2:')
    console.log('     ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: sato.hanako@company.com')
    console.log('     ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: password')

  } catch (error) {
    console.error('âŒ åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error)
    throw error
  }
}

main()
  .then(async () => {
    await prisma.$disconnect()
  })
  .catch(async (e) => {
    console.error('âŒ åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', e)
    await prisma.$disconnect()
    throw e
  })
'''

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='SQLã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Prisma seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ')
    parser.add_argument('--sql-dir', default='docs/design/database/data', 
                       help='SQLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (default: docs/design/database/data)')
    parser.add_argument('--output', default='src/database/prisma/seed.ts',
                       help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ« (default: src/database/prisma/seed.ts)')
    parser.add_argument('--backup', action='store_true',
                       help='æ—¢å­˜ã®seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—')
    
    args = parser.parse_args()
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    if args.backup and os.path.exists(args.output):
        backup_file = f"{args.output}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.rename(args.output, backup_file)
        print(f"Backup created: {backup_file}")
    
    # å¤‰æ›å®Ÿè¡Œ
    converter = SQLToSeedConverter(args.sql_dir, args.output)
    converter.generate_seed_file()
    
    print("âœ… seed.tsãƒ•ã‚¡ã‚¤ãƒ«ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.output}")
    print("ğŸš€ å®Ÿè¡Œæ–¹æ³•: npm run db:seed")

if __name__ == '__main__':
    main()
